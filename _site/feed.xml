<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-05-21T01:03:04+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Statistics and Machine Learning Lab by cwyoon96</title><subtitle>통계학 그리고 머신러닝 공부 내용을 정리하는 블로그입니다.</subtitle><author><name>cwyoon96</name></author><entry><title type="html">PRML 스터디 Chap.6.4</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-4/" rel="alternate" type="text/html" title="PRML 스터디 Chap.6.4" /><published>2022-03-16T00:00:00+09:00</published><updated>2022-03-16T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-4</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-4/"><![CDATA[<h3 id="645-gaussian-processes-for-classification">6.4.5 Gaussian processes for classification</h3>

<p>이번 절에서는 Gaussian process를 이용하여 classification 문제를 푸는 방법을 소개한다. 기본적으로 Gaussian process는 real axis 전체에서 prediction을 하기 때문에 sigmoid function $\sigma(x)$을 이용해 probability를 predict 할 수 있도록 해야한다. Function $a(\mathbf{x})$에 대한 Gaussian process를 구했다고 가정하면, target variable $t$의 분포는 Bernoulli distribution</p>

\[p(t|a) = \sigma(a)^{t}(1 - \sigma(a))^{1-t}\]

<p>로 나타날 것이다.</p>

<p>먼저 $\mathbf{a}_{N+1}$에 대한 Gaussian process prior는</p>

\[p(\mathbf{a}_{N+1}) = \mathcal{N}(\mathbf{a}_{N+1}|\mathbf{0},\mathbf{C}_{N+1})\]

<p>로 정의된다. 하지만 regression case와는 다르게 covariance matrix에 noise가 추가되지는 않는다 (모든 label이 correct하다고 가정). 하지만, covariance matrix가 positive definite임을 확실시하기 위해 noise와 유사한 term $\nu$를 추가해</p>

\[C(\mathbf{x}_n,\mathbf{x}_m) = k(\mathbf{x}_n,\mathbf{x}_m) + \nu \delta_{nm}\]

<p>으로 covariance matrix $\mathbf{C}_{N+1}$을 정의한다.</p>

<p>이제, predictive distribution은</p>

\[p(t_{N+1} = 1|\mathbf{t}_N) = \int p(t_{N+1} = 1|a_{N+1})p(a_{N+1}|\mathbf{t}_{N})da_{N+1}\]

<p>where</p>

\[p(t_{N+1} = 1|a_{N+1}) = \sigma(a_{N+1})\]

<p>으로 주어진다. 하지만 이 적분은 intractable 하기 때문에 posterior distribution 
$p(a_{N+1}|\mathbf{t}_N)$
에 대한 Gaussian approximation을 진행해야 한다. 이를 위해 <em>variational inference</em>, <em>expectation propagation</em> 등을 사용할 수도 있지만, 여기서는 Laplace approximation을 통한 방법을 알아보자.</p>

<h3 id="646-laplace-approximation">6.4.6 Laplace approximation</h3>

<p>Bayes’ theorem을 통해 $a_{N+1}$에 대한 posterior distribution은</p>

\[\begin{aligned}
p(a_{N+1}|\mathbf{t}_N) &amp;= \int p(a_{N+1},\mathbf{a}_N | \mathbf{t}_N)d\mathbf{a}_{N} \\ &amp;= \cfrac{1}{p(\mathbf{t}_N)} \int p(a_{N+1},\mathbf{a}_N)p(\mathbf{t}_N | a_{N+1},\mathbf{a}_N)d\mathbf{a}_{N} \\ &amp;= \cfrac{1}{p(\mathbf{t}_N)} \int p(a_{N+1}| \mathbf{a}_N)p(\mathbf{a}_N)p(\mathbf{t}_N | \mathbf{a}_N)d\mathbf{a}_N \\ &amp; = \int p(a_{N+1}| \mathbf{a}_N)p(\mathbf{a}_N|\mathbf{t}_N)d\mathbf{a}_N \ \ \ - (*)
\end{aligned}\]

<p>로 정리된다. 2번째에서 3번째 줄으로 넘어갈 때는</p>

\[p(\mathbf{t}_N|a_{N+1},\mathbf{a}_N) = p(\mathbf{t}_N|\mathbf{a}_N)\]

<p>임을 사용했다. 또한, regression case에서 정리한 결과를 이용해 conditional distribution 
$p(a_{N+1}|\mathbf{a}_N)$
은</p>

\[p(a_{N+1}|\mathbf{a}_N) = \mathcal{N}(a_{N+1}|\mathbf{k}^{T}\mathbf{C}_{N}^{-1}\mathbf{a}_N, c - \mathbf{k}^{T}\mathbf{C}_{N}^{-1}\mathbf{k})\]

<p>로 주어진다. 따라서 posterior distribution 
<span>$p(\mathbf{a}_N|\mathbf{t}_N)$</span>
에 대한 Laplace approximation을 구하면 (*)식에 따라 적분을 하여 
<span>$a_{N+1}$</span>
에 대한 posterior distribution을 구할 수 있음을 알 수 있다.</p>

<p>Prior $p(\mathbf{a}_N)$는 zero mean에 covariance matrix $\mathbf{C}_N$으로 주어지며, data term은</p>

\[p(\mathbf{t}_N | \mathbf{a}_N) = \prod_{n = 1}^{N}\sigma(a_n)^{t_n}(1-\sigma(a_n))^{1-t_n} = \prod_{n=1}^{N}e^{a_n t_n}\sigma(-a_n)\]

<p>으로 주어진다. 이제, additive normalization constant 
$p(\mathbf{t}_N)$
를 제외한 
$p(\mathbf{a}_N|\mathbf{t}_N)$
의 logarithm에 대한 Taylor exansion을 하면</p>

\[\begin{aligned}
\Psi(\mathbf{a}_N) &amp;= ln \ p(\mathbf{a}_N) + ln \ p(\mathbf{t}_N|\mathbf{a}_N) \\ &amp;= -\cfrac{1}{2}\mathbf{a}_{N}^{T}\mathbf{C}_{N}^{-1}\mathbf{a}_N - \cfrac{N}{2}ln(2\pi) - \cfrac{1}{2}ln |\mathbf{C}_N| + \mathbf{t}_{N}^{T}\mathbf{a}_N \\ &amp;-\sum_{n=1}^{N}ln(1 + e^{a_n}) + const 
\end{aligned}\]

<p>로 주어짐을 알 수 있다.</p>

<p>먼저, posterior distribution의 mode 값을 구하기 위해 graident를 계산하면</p>

\[\bigtriangledown \Psi(\mathbf{a}_N) = \mathbf{t}_N - \boldsymbol{\sigma}_N - \mathbf{C}_{N}^{-1}\mathbf{a}_N\]

<p>으로 주어지는데, $\sigma(a_n)$의 벡터 형태인 $\boldsymbol{\sigma}_N$가 $\mathbf{a}_N$에 nonlinear하게 depend하기 때문에 단순히 gradient를 0으로 두는 것 만으로는 mode를 구할 수 없다. 따라서 Newton-Raphson 방법과 같은 알고리즘을 써야하는데 이를 위해 second derivative</p>

\[\bigtriangledown \bigtriangledown \Psi(\mathbf{a}_N) = -\mathbf{W}_N - \mathbf{C}_{N}^{-1}\]

<p>where $\mathbf{W}_N$ is a diagonal matrix with elements $\sigma(a_n)(1-\sigma(a_n))$</p>

<p>를 사용해야 한다. 이때, diagonal element가 (0,1/4) 범위 내에서만 존재하기 때문에 $\mathbf{W}_N$은 poistive definite 임을 알 수 있다. 또한 $\mathbf{C}_N$도 p.d. 이기 때문에 (역행렬도 p.d.), 그 합 또한 p.d. 임을 알 수 있다. 따라서 Hessian matrix $A = - \bigtriangledown \bigtriangledown \Psi(\mathbf{a}_N)$가 p.d.임을 알 수 있고 posterior distribution이 log convex하여 유일한 global maxima를 가짐을 알 수 있다. 하지만, Hessian이 $\mathbf{a}_N$에 대한 function으로 주어지기에 posterior는 여전히 Gaussian은 아니다.</p>

<p>이제, 4장에서 다뤘던 Newton-Raphsonn formula를 이용한 $\mathbf{a}_N$에 대한 iterative update 식은</p>

\[\mathbf{a}_{N}^{new} = \mathbf{C}_N(\mathbf{I} + \mathbf{W}_N \mathbf{C}_N)^{-1}\{\mathbf{t}_N - \boldsymbol{\sigma}_N + \mathbf{W}_N \mathbf{a}_N \}\]

<p>으로 주어진다. Mode 값 $\mathbf{a}_N^{*}$에서는 gradient 값은 0이 될 것이기 때문에</p>

\[\mathbf{a}_N^{*} = \mathbf{C}_N (\mathbf{t}_N - \boldsymbol{\sigma}_N)\]

<p>식이 성립할 것이다. 이제 $\mathbf{a}_N^{*}$에서의 Hessian matrix $H$를 계산하면 posterior distribution에 대한 Gaussian approximation은</p>

\[q(\mathbf{a}_N) = \mathcal{N}(\mathbf{a}_N | \mathbf{a}_N^{*},H^{-1})\]

<p>으로 구할 수 있다.</p>

<p>이제, 원래 구하고자 하였던 
$p(a_{N+1}|\mathbf{t}_N)$
은 linear-Gaussian model에 따라</p>

\[\begin{aligned}
\mathbb{E}[a_{N+1}|\mathbf{t}_N] &amp;= \mathbf{k}^{T}(\mathbf{t}_N - \boldsymbol{\sigma}_N) \\ \text{var}[a_{N+1}|\mathbf{t}_N] &amp;= c - \mathbf{k}^{T}(\mathbf{W}_N^{-1} + \mathbf{C}_N)^{-1}\mathbf{k}
\end{aligned}\]

<p>의 값을 가지는 Gaussian distribution으로 approximate 할 수 있다. 최종적으로 predictive distribution은 6.4.5절에서 주어진 적분식을 통해 구할 수 있다.</p>

<p>Regression case에서와 마찬가지로 classification case에서도 covariance function에 들어간 parameter $\boldsymbol{\theta}$를 최적화하는 작업을 해야한다. Likelihood function은</p>

\[p(\mathbf{t}_N|\boldsymbol{\theta}) = \int p(\mathbf{t}_N|\mathbf{a}_N)p(\mathbf{a}_N|\boldsymbol{\theta})d\mathbf{a}_N\]

<p>으로 주어지는데, 역시 적분이 intractable하기 때문에 다시 Laplace approximation을 사용한다. 4.4절에서 정리한 결과를 다시 이용하여</p>

\[ln \ p(\mathbf{t}_N|\boldsymbol{\theta}) = \Psi(\mathbf{a}_N^{*}) - \cfrac{1}{2}ln|\mathbf{W}_N + \mathbf{C}_{N}^{-1}| + \cfrac{N}{2}ln(2\pi)\]

<p>where</p>

\[\Psi(\mathbf{a}_N^{*}) = ln \ p(\mathbf{a}_N^{*}|\boldsymbol{\theta}) + ln \ p(\mathbf{t}_N|\mathbf{a}_N^{*})\]

<p>으로 주어진다. 이제 gradient를 구하면 되는데, covariance matrix $\mathbf{C}_N$의 $\boldsymbol{\theta}$에 대한 explicit한 dependence로 인한 term과 $\mathbf{a}_N^{*}$의 $\boldsymbol{\theta}$에 대한 dependence로 인한 term 2가지를 생각할 수 있다.</p>

<p>먼저, explicit dependence term은</p>

\[\begin{aligned}
\cfrac{\partial ln \ p(\mathbf{t}_N|\boldsymbol{\theta})}{\partial \theta_j} \ = \ &amp;\cfrac{1}{2}\mathbf{a}_{N}^{*T}\mathbf{C}_{N}^{-1}\cfrac{\partial \mathbf{C}_N}{\partial \theta_j}\mathbf{C}_{N}^{-1}\mathbf{a}_{N}^{*} \\ &amp;- \cfrac{1}{2}Tr\bigg[ (\mathbf{I} + \mathbf{C}_N\mathbf{W}_N)^{-1}\mathbf{W}_N\cfrac{\partial \mathbf{C}_N}{\partial \theta_j} \bigg]
\end{aligned}\]

<p>으로 주어진다.</p>

<p><span>$\mathbf{a}_N^{*}$</span>
의 parameter에 대한 dependence로 인한 term에서 
<span>$\Psi(\mathbf{a}_N)$</span>
는 
<span>$\mathbf{a}_N^{*}$</span>
에서 gradient가 0이 되도록 Laplace approximation을 사용했기 때문에, 2번째 term에 대해서만 계산하면 된다는 것을 알 수 있다. 2번째 term에 대한 gradient는</p>

\[\begin{aligned}
-\cfrac{1}{2}&amp;\sum_{n = 1}^{N} \cfrac{\partial ln|\mathbf{W}_N + \mathbf{C}_N^{-1}|}{\partial a_{n}^{*}}\cfrac{\partial a_n^*}{\partial \theta_j} \\ &amp;= -\cfrac{1}{2}\sum_{n=1}^{N}\big[ (\mathbf{I}+ \mathbf{C}_N\mathbf{W}_N)^{-1}\mathbf{C}_N \big]_{nn}\sigma_{n}^{*}(1 - \sigma_{n}^{*})(1-2\sigma_{n}^{*})\cfrac{\partial a_{n}^{*}}{\partial \theta_j}
\end{aligned}\]

<p>으로 구할 수 있다. 또한, 위에 주어진 $\mathbf{a}_N^{*}$에 대한 식을 이용하여</p>

\[\cfrac{\partial a_{n}^{*}}{\partial \theta_j} = (\mathbf{I} + \mathbf{W}_N \mathbf{C}_N)^{-1}\cfrac{\partial \mathbf{C}_N}{\partial \theta_j}(\mathbf{t}_N - \boldsymbol{\sigma}_N)\]

<p>임을 알 수 있다. 이제 필요한 모든 term들을 구했으므로 graident를 계산할 수 있고, nonlinear optimization algorithm을 이용해 최적의 $\boldsymbol{\theta}$를 구해주면 된다.</p>

<h3 id="647-connection-to-neural-networks">6.4.7 Connection to neural networks</h3>

<p>Neural network 파트에서 hidden unit의 개수 M을 충분히 늘리면 two-layer network가 어떤 function이든 approximate할 수 있다는 것을 배웠었다. Neal (1996)은 Bayesian neural network에서 $\mathbf{w}$에 대한 특정 prior distribution들을 가정하였을 때, neural network에서 생성된 함수의 분포가 M이 무한대에 가까워짐에 따라 Gaussian process를 따르게 된다는 것을 밝혀냈다. 하지만, M이 무한대로 가면 output은 서로 indenpendent 하게 될 것이고 이렇게 되면 같은 hidden unit을 공유한다는 neural network의 장점을 살리지 못한다는 장점이 있다.</p>

<p>또한, Gaussian process는 covariance function (kernel function)을 어떻게 정의하냐에 따라 결과가 달라지는 것을 확인했는데, Willianms (1998)는 hidden unit activation function을 probit 혹은 Gaussian으로 설정하는 지에 따른 covariance function의 explicit form을 제시하였다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[6.4.5 Gaussian processes for classification]]></summary></entry><entry><title type="html">PRML 스터디 Chap.6.1-2</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-1-2/" rel="alternate" type="text/html" title="PRML 스터디 Chap.6.1-2" /><published>2022-03-03T00:00:00+09:00</published><updated>2022-03-03T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-1-2</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-6-1-2/"><![CDATA[<h1 id="6-kernel-methods">6. Kernel Methods</h1>

<p>고정된 비선형 feature space mapping을 $\phi(\mathbf{x})$라 할때, kernel function은</p>

\[k(\mathbf{x},\mathbf{x}') = \phi(\mathbf{x})^{T}\phi(\mathbf{x}')\]

<p>로 정의된다. (여기서 $\mathbf{x}’$는 $\mathbf{x}^T$의 의미가 아니라 임의의 다른 vector를 의미한다.) 정의상 kernel function은 기본적으로 symmetric 하다는 것을 알 수 있다. Kernel function의 가장 간단한 형태로는 identity mapping을 이용한 linear kernel</p>

\[k(\mathbf{x},\mathbf{x}') = \mathbf{x}^{T}\mathbf{x}'\]

<p>을 생각할 수 있을 것이다.</p>

<p>많은 kernel들은 argument 간의 differencea만으로 정의되는 
$k(\mathbf{x},\mathbf{x}’) = k(\mathbf{x} - \mathbf{x}’)$
의 형태를 가지고 있는데 이를 <em>stationary kernel</em> 이라 부른다. 더 나아가 <em>radial basis functions</em>로도 알려진 <em>homogeneous</em> kernel들은 
$k(\mathbf{x},\mathbf{x}’) = k(||\mathbf{x} - \mathbf{x}’||)$
 와 같이 distance의 magnitude에만 의존하는 형태를 가지고 있다. 이는 kernel function이 2개 input 간의 similarity를 재는 function으로 사용되기 때문이다.</p>

<h2 id="61-dual-representations">6.1. Dual Representations</h2>

<p>많은 linear model들은 kernel function으로 표현되는 dual representation을 가지고 있다. Linear regression을 예로 들자면</p>

\[J(\mathbf{w}) = \cfrac{1}{2} \sum_{n=1}^{N}\{ \mathbf{w}^{T}\phi(\mathbf{x}_n) - t_n \}^2 + \cfrac{\lambda}{2}\mathbf{w}^{T}\mathbf{w}\]

<p>에서 graient가 0이 되는 지점은</p>

\[\mathbf{w} = -\cfrac{1}{\lambda}\sum_{n=1}^{N}\{ \mathbf{w}^{T}\phi(\mathbf{x}_n) - t_n \}\phi(\mathbf{x}_n) = \sum_{n=1}^{N}a_n\phi(\mathbf{x}_n) = \Phi^T\mathbf{a}\]

<p>으로 나타낼 수 있다.</p>

<p>이제 $\mathbf{w}$를 원래 sum-of-square 식에 subtitue하면</p>

\[J(\mathbf{a}) = \cfrac{1}{2}\mathbf{a}^T\mathbf{K}\mathbf{K}\mathbf{a} - \mathbf{a}^{T}\mathbf{K}\mathbf{t} + \cfrac{1}{2}\mathbf{t}^{T}\mathbf{t} + \cfrac{\lambda}{2}\mathbf{a}^{T}\mathbf{K}\mathbf{a}\]

<p>where</p>

\[\mathbf{K} = \Phi\Phi^T \ \text{while} \ K_{nm} = k(\mathbf{x}_n,\mathbf{x}_m)\]

<p>로 표현할 수 있다. (여기서 $\mathbf{K}$를 gram matrix라고 한다.)</p>

<p>다시 해당 식의 gradient를 0으로 두면 solution은</p>

\[\mathbf{a} = (\mathbf{K} + \lambda \mathbf{I}_N)^{-1}\mathbf{t}\]

<p>로 주어진다.</p>

<p>해당 solution을 linear regression model에 대입하여 new input $\mathbf{x}$에 대한 prediction을 하면</p>

\[y(\mathbf{x}) = \mathbf{w}^{T}\phi(\mathbf{x}) = \mathbf{a}^{T}\Phi\phi(\mathbf{x}) = \mathbf{k}(\mathbf{x})^{T}(\mathbf{K} + \lambda\mathbf{I}_N)^{-1}\mathbf{t}\]

<p>where</p>

\[k_n(\mathbf{x}) = k(\mathbf{x_n},\mathbf{x}) \ \text{is element of } \mathbf{k(\mathbf{x})}\]

<p>로 주어진다. 따라서 least-squares problem에 대한 dual formulation은 kernel function만을 가지고도 표현될 수 있다는 것을 알 수 있다. 이는 feature vector $\phi(\mathbf{x})$의 explicit introduction 없이도 kernel function을 직접적으로 control 하여 답을 찾을 수 있음을 의미하는데, 이를 <em>kernel trick</em>이라 한다.</p>

<h2 id="62-constructing-kernels">6.2. Constructing Kernels</h2>

<p>Kernel function을 직접적으로 construct하기 위해서는 해당 function이 valid한 kernel인지, 즉 feature space 상의 scalar product로 표현될 수 있는지 확인해야한다. 다행히 이를 직접 확인할 필요 없이, Gram matrix $\mathbf{K}$가 어떤 set ${\mathbf{x}_n}$을 통해 construct 하던지 poisitve semidefinite 함을 보이면 해당 kernel function은 valid kernel임이 알려져 있다.</p>

<p>새로운 kernel function을 construct하는데 유용한 사실 중 하나는 간단한 형태의 kernel을 building block으로 사용하여 복잡한 kernel을 만들어 낼 수 있다는 것이다.</p>

<p><img src="/assets/img/2022-03-03-prml-스터디-chap-6-1-2/Kernel_Techniques.png" alt="" /></p>

<p>예를 들어 임의의 degree $M$의 polynoimal kernel</p>

\[k(\mathbf{x},\mathbf{x}') = (\mathbf{x}^T \mathbf{x}' + c)^{M} \ \text{with} \ c &gt; 0\]

<p>역시 위의 technique을 통해 valid kernel임을 알 수 있다.</p>

<p>많이 사용되는 또 다른 kernel은</p>

\[k(\mathbf{x},\mathbf{x}') = \text{exp}(-||\mathbf{x} - \mathbf{x}'||^2/2\sigma^2)\]

<p>의 형태를 가진 kernel로 ‘Gaussian kernel’로 불린다. Gaussian kernel은 infinite dimensionality를 가지는 feature vector간의 inner product와 동일함이 알려져 있어 매우 유용하게 사용된다. Gaussian kernel은 Euclidean distance에 국한되지 않고 다른 nonlinear kernel $\kappa(\mathbf{x},\mathbf{x}’)$을 이용하여</p>

\[k(\mathbf{x},\mathbf{x}') = \text{exp}\bigg\{-\cfrac{1}{2\sigma^2}(\kappa(\mathbf{x},\mathbf{x}) + \kappa(\mathbf{x}',\mathbf{x}') - 2\kappa(\mathbf{x},\mathbf{x}')) \bigg\}\]

<p>의 더 복잡한 형태를 가질 수도 있다.</p>

<p>Kernel method의 중요한 contribution 중 하나는 단순한 real number가 아닌 graph, sets, strings, text documents와 같은 symbolic input까지 처리 가능하다는 것이다. 예를 들어 $A_1,A_2$가 subset이라고 할 때,</p>

\[k(A_1,A_2) = 2^{|A_1 \cap A_2|}\]

<p>은 valid kernel function으로서 그 역할을 할 수 있다.</p>

<p>Kernel을 construct하는 강력한 방식 중 하나는 probabilistic generative model에서부터 시작하는 방식이다. Generative model $p(\mathbf{x})$가 주어졌을 때, kernel function을</p>

\[k(\mathbf{x},\mathbf{x}') = p(\mathbf{x})p(\mathbf{x}')\]

<p>처럼 정의하면 이는 valid kernel function이다. 이를 다시 위의 technique을 이용하여</p>

\[k(\mathbf{x},\mathbf{x}') = \sum_{i}p(\mathbf{x}|i)p(\mathbf{x}'|i)p(i)\]

<p>로 extend할 수 있는데, 이는 $i$가 latent variable의 역할을 하는 factorizable한 mixture distribution으로 생각할 수 있다. 여기서 sum을 무한번 한다고 생각하면 continuous한 latent variable에 대한</p>

\[k(\mathbf{x},\mathbf{x}') = \int p(\mathbf{x}|\mathbf{z})p(\mathbf{x}'|\mathbf{z})p(\mathbf{z})d\mathbf{z}\]

<p>kernel function 형태을 생각할 수 있다.</p>

<p>Kernel function을 define 하는데 generative model을 사용하는 또 다른 방법은 <em>Fisher kernel</em>로 알려진 방법이다. Parametric generative model 
$p(\mathbf{x}|\boldsymbol{\theta})$
가 있다고 했을 때, generative model에서 생성된 input vector들 간의 similarity를 재는 kernel function을 생각해보자. 이를 위해 <em>Fisher score</em></p>

\[\mathbf{g}(\boldsymbol{\theta},\mathbf{x}) = \bigtriangledown_{\theta} \ ln \ p(\mathbf{x}|\boldsymbol{\theta})\]

<p>와 <em>Fisher information matrix</em></p>

\[\mathbf{F} = \mathbb{E}_{p(\mathbf{x}|\boldsymbol{\theta})} [\mathbf{g}(\boldsymbol{\theta},\mathbf{x})\mathbf{g}(\boldsymbol{\theta},\mathbf{x})^{T}]\]

<p>를 통해 정의된 Fisher kernel</p>

\[k(\mathbf{x},\mathbf{x}') = \mathbf{g}(\boldsymbol{\theta},\mathbf{x})^T \mathbf{F}^{-1} \mathbf{g}(\boldsymbol{\theta},\mathbf{x}')\]

<p>를 생각할 수 있다. Fisher kenel은 Fisher information matrix로 인해 density model의 nonlinear re-parametrization 
$\boldsymbol{\theta} \rightarrow \boldsymbol{\psi}(\boldsymbol{\theta})$
 에 대해 invariant 하다는 특성을 가지고 있다.</p>

<p>실제로는 Fisher information matrix를 계산하기 어렵기 때문에 sample average를 통해</p>

\[\mathbf{F} \simeq \cfrac{1}{N} \sum_{n = 1}^{N}  \mathbf{g}(\boldsymbol{\theta},\mathbf{x}_n) \mathbf{g}(\boldsymbol{\theta},\mathbf{x}_n)^{T}\]

<p>로 대체하거나 Fisher information matrix 자체를 생략해 noninvariant 한 kernel</p>

\[k(\mathbf{x},\mathbf{x}') = \mathbf{g}(\boldsymbol{\theta},\mathbf{x})^{T}\mathbf{g}(\boldsymbol{\theta},\mathbf{x}')\]

<p>을 사용하기도 한다.</p>

<p>마지막으로 소개할 kernel은 sigmoidal kernel로</p>

\[k(\mathbf{x},\mathbf{x}') = \text{tanh}(a\mathbf{x}^{T}\mathbf{x}' +b)\]

<p>의 형태를 가지고 있으며 Gram matrix가 보통 positive semidefinite 하지 않다. 하지만, 해당 kernel을 통해 support vector machine이 neural network model을 resemble 한다는 것을 보일 수 있기 때문에 많이 사용되고 있다. 곧 보이겠지만 basis function의 개수를 무한개로 보냈을 때, 적절한 prior를 설정하면 Bayesian neural network가 Gaussian process로 reduce 한다는 것을 보일 수 있는데, 이는 kernel method과 neural network 사이에 깊은 관계가 있음을 암시한다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[6. Kernel Methods]]></summary></entry><entry><title type="html">PRML 스터디 Chap.5.7</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-7/" rel="alternate" type="text/html" title="PRML 스터디 Chap.5.7" /><published>2022-02-24T00:00:00+09:00</published><updated>2022-02-24T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-7</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-7/"><![CDATA[<h3 id="555-training-with-transformed-data">5.5.5 Training with transformed data</h3>

<p>Model에 transformation invariance를 유도하는 또 다른 방법으로 당연히 transformed 된 데이터를 함께 학습에 이용하는 것을 생각할 수 있다. 이번 절에서는 해당 방법이 5.5.4절에서 다뤘던 tangent propagation과 매우 긴밀하게 연결되어 있다는 것을 보일 것이다.</p>

<p>5.5.4절에서와 같은 transformation을 가정하고, sum-of-square error function을 사용한다고 하면 untransformed inputs를 이용한 이론적인 error function은</p>

\[E = \cfrac{1}{2}\int \int \{y(\mathbf{x})-t\}^{2} p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt\]

<p>로 주어진다. (single output 가정)</p>

<p>이제 $\xi$가 distribution $p(\xi)$ (zero mean with samll variance)에서 draw 되었다고 가정하면, 확장된 error function은</p>

\[\tilde{E} = \cfrac{1}{2} \int \int \int \{y(\mathbf{s}(\mathbf{x},\xi)) - t\}^2 p(t|\mathbf{x})p(\mathbf{x})p(\xi)d\mathbf{x}dtd\xi\]

<p>로 쓸 수 있다.</p>

<p>이때, tranformation function $\mathbf{s}$에 대한 Taylor expansion을 통해</p>

\[\begin{aligned}
\mathbf{s}(\mathbf{x},\xi) &amp;= \mathbf{s}(\mathbf{x},0) + \left. \xi \cfrac{\partial}{\partial \xi} \mathbf{s}(\mathbf{x},\xi)\right|_{\xi = 0} + \left. \cfrac{\xi^2}{2} \cfrac{\partial^2}{\partial \xi^2} \mathbf{s}(\mathbf{x},\xi)\right|_{\xi = 0} + O(\xi^3) \\
&amp;= \mathbf{x} + \xi \boldsymbol{\tau} + \cfrac{1}{2}\xi^2\boldsymbol{\tau'} + O(\xi^3)
\end{aligned}\]

<p>로 쓸 수 있어</p>

\[y(\mathbf{s}(\mathbf{x},\xi)) = y(\mathbf{x}) + \xi \boldsymbol{\tau}^{T} \bigtriangledown y(\mathbf{x}) + \cfrac{\xi^2}{2}\bigg[ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \bigg] + O(\xi^3)\]

<p>로 model function을 쓸 수 있게 된다. 이제 이를 error function에 plug-in 하면</p>

\[\begin{aligned}

\tilde{E} &amp;= \cfrac{1}{2} \int \int \{ y(\mathbf{x}) - t \}^2p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt \\
&amp;+ \mathbb{E}[\xi] \int \int \{ y(\mathbf{x}) - t \} \boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x})p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt \\
&amp;+ \mathbb{E}[\xi^2] \int \int \bigg[ \{y(\mathbf{x}) - t\}\cfrac{1}{2} \big\{ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \big\} + \\ &amp;(\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 \bigg]p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt + O(\xi^3)

\end{aligned}\]

<p>로 주어진다. 이때, 가정에 따라 $\mathbb{E}[\xi] = 0$ 임을 이용하고 $\mathbb{E}[\xi^2]$를 $\lambda$로 denote 하면 5.5.4절에서 보았던</p>

\[\tilde{E} = E + \lambda \Omega \ \ \ \ \ \ \ \ \ - (*)\]

<p>where</p>

\[\begin{aligned}

\Omega = &amp;\int \bigg[ \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\cfrac{1}{2} \big\{ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \big\} \\ &amp;+ (\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 \bigg]p(\mathbf{x})d\mathbf{x}

\end{aligned}\]

<p>의 형태가 됨을 알 수 있다. ($t$로 적분하고 $O(\xi^3)$ omit)</p>

<p>앞서 1절에서 sum-of-square error를 최소한으로 하는 것은 
$\mathbb{E}[t|\mathbf{x}]$
임을 밝혔다. 이에 위 (*)식으로부터 reuglarized error를 최소한으로 하는 network function은</p>

\[y(\mathbf{x}) = \mathbb{E}[t|\mathbf{x}] + O(\xi)\]

<p>임을 알 수 있고, $\xi$의 최고차항을 기준으로 regularizer의 first term이 사라져</p>

\[\Omega = \cfrac{1}{2} \int (\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 p(\mathbf{x})d\mathbf{x}\]

<p>로 주어져 5.5.4절에서 보았던 tangent propagation regularizer와 완벽히 일치함을 알 수 있다.</p>

<h2 id="57-bayesian-neural-networks">5.7 Bayesian Neural Networks</h2>

<p>현재까지는 MLE에 기반하여 Neural Network를 공부하였지만, 5.7절에서는 Bayesian Neural Network를 다룬다. Neural Network는 그 자체의 nonlinearity로 인해 Linear regression과 다르게 Bayesian treatment를 그대로 적용하기 어렵다. 이에 이번 절에서는 Laplace approximation을 통해 Bayesian Neural Network를 어떻게 implement 할 수 있는지 살펴볼 것이다.</p>

<h3 id="571-posterior-parameter-distribution">5.7.1 Posterior parameter distribution</h3>

<p>먼저 single output regression 문제를 생각해보자. 이때,</p>

\[p(t|\mathbf{x},\mathbf{w},\beta) = N(t|y(\mathbf{x},\mathbf{w}),\beta^{-1})\]

<p>로 가정한다. 또한, 이전 Bayesian linear regression에서 처럼</p>

\[p(\mathbf{w}|\alpha) = N(\mathbf{w}|\mathbf{0},\alpha^{-1}\mathbf{I})\]

<p>로 가정하자. i.i.d. 한 $N$개의 observation에 대해서 target values를 $\mathbf{D} = {t_1,…,t_N}$로 notate 하면 최종적인 posterior distribution은 자연스럽게</p>

\[p(\mathbf{w}|\mathbf{D},\alpha,\beta) \propto p(\mathbf{w}|\alpha)p(\mathbf{D}|\mathbf{w},\beta)\]

<p>로 주어진다. 하지만, $y(\mathbf{x},\mathbf{w})$가 $\mathbf{w}$에 대해 nonlinear하게 dependent하기 때문에 posterior distribution은 더 이상 Gaussian distribution을 따르지 않게 되고 Laplace approximation을 통해 Gaussian approximation을 진행해야한다.</p>

\[ln \ p(\mathbf{w}|\mathbf{D}) = -\cfrac{\alpha}{2} \mathbf{w}^{T}\mathbf{w} - \cfrac{\beta}{2} \sum_{n=1}^{N}\{y(\mathbf{x}_n, \mathbf{w})- t_n\}^2 + \text{const}\]

<p>로 주어지는 log posterior를 maximize 하는 $\mathbf{w}_{MAP}$를 앞서 소개한 optimization 방법들을 통해 구했다고 하자. 이제 negative log posterior의 second derivative matrix를 구해야 한다. 이는</p>

\[\mathbf{A} = -\bigtriangledown \bigtriangledown ln \ p(\mathbf{w}|\mathbf{D},\alpha,\beta) = \alpha \mathbf{I} + \beta \mathbf{H}\]

<p>로 구해지는데, 여기서 $\mathbf{H}$는 sum-of-square를 $\mathbf{w}$로 2차 미분한 Hessian이다.</p>

<p>이제 4장에서 다룬 Laplace approximation을 통해</p>

\[q(\mathbf{w}|\mathbf{D}) = N(\mathbf{w}|\mathbf{w}_{MAP},\mathbf{A}^{-1})\]

<p>로 posterior를 approximate 할 수 있다.</p>

<p>이제 predictive distribution</p>

\[p(t|\mathbf{x},\mathbf{D}) = \int p(t|\mathbf{x},\mathbf{w})q(\mathbf{w}|\mathbf{D})d\mathbf{w}\]

<p>를 구할 수 있는데, 문제는 Gaussian approximation을 한 이후에도 $y(\mathbf{x},\mathbf{w})$의 nonlinearity로 인해 해당 적분이 intractable 하다는 것이다. 이에 posterior distribution이 작은 분산을 가지고 있다고 가정하고, Taylor expansion을 통해</p>

\[y(\mathbf{x},\mathbf{w}) \simeq y(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{g^{T}}(\mathbf{w} - \mathbf{w}_{MAP})\]

<p>where</p>

\[\mathbf{g} = \bigtriangledown_{\mathbf{w}}y(\mathbf{x},\mathbf{w})|_{\mathbf{w} = \mathbf{w}_{MAP}}\]

<p>로 linear term만 남기는 approximation을 생각한다. 이제 linear-Gaussian model로서 
$p(t|\mathbf{w})$
의 mean이 
$\mathbf{w}$
에 대해 linear한 형태</p>

\[p(t|\mathbf{x},\mathbf{w},\beta) \simeq N(t|y(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{g^{T}}(\mathbf{w} - \mathbf{w}_{MAP}), \beta^{-1})\]

<p>가 될 것이며, 2장에서의 linear-Gaussian model에 대한 정리를 이용해</p>

\[p(t|\mathbf{x},\mathbf{D},\alpha,\beta) = N(t|y(\mathbf{x},\mathbf{w}_{MAP}), \sigma^2(\mathbf{x}))\]

<p>where</p>

\[\sigma^2(\mathbf{x}) = \beta^{-1} + \mathbf{g}^{T}\mathbf{A}^{-1}\mathbf{g}\]

<p>로 predictive distribution을 구할 수 있다.</p>

<h3 id="572-hyperparameter-optimization">5.7.2 Hyperparameter optimization</h3>

<p>지금까지는 $\alpha,\beta$가 알려져있고 고정되어있다고 가정하였다. 하지만, 3.5절에서 다뤘던 것처럼 해당 hyperparameter에 대해 최적의 값을 찾을 수 있다. Hyperparameter에 대한 evidence는</p>

\[p(\mathbf{D}|\alpha,\beta) = \int p(\mathbf{D}|\mathbf{w},\beta)p(\mathbf{w}|\alpha)d\mathbf{w}\]

<p>로 구할 수 있고, 역시 Laplace approximation을 통해</p>

\[ln \ p(\mathbf{D}|\alpha,\beta) \simeq -E(\mathbf{w}_{MAP}) - \cfrac{1}{2} ln |\mathbf{A}| + \cfrac{W}{2} ln \ \alpha + \cfrac{N}{2} ln \ \beta - \cfrac{N}{2} ln(2\pi)\]

<p>where</p>

\[E(\mathbf{w}) = \cfrac{\alpha}{2} \mathbf{w}^{T}\mathbf{w} + \cfrac{\beta}{2} \sum_{n=1}^{N}\{y(\mathbf{x}_n, \mathbf{w})- t_n\}^2\]

<p>를 구할 수 있는데, 이는 3장에서의 linear regression model에서와 동일한 형태임을 알 수 있다. 이에 3.5절에서와 마찬가지로 최적의 $\alpha$는</p>

\[\alpha = \cfrac{\gamma}{\mathbf{w}_{MAP}^{T}\mathbf{w}_{MAP}}\]

<p>where</p>

\[\gamma = \sum_{i = 1}^{W}\cfrac{\lambda_i}{\alpha + \lambda_i}\]

<p>로 구할 수 있다. 여기서 $\lambda_i$는 sum-of-squares error function을 2번 미분하여 $\mathbf{w} = \mathbf{w}_{MAP}$에서 evaluate한 Hessian matrix $\mathbf{H}$의 eigenvalue로,</p>

\[\beta \mathbf{H}\mathbf{u}_{i} = \lambda_{i}\mathbf{u}_i\]

<p>에서 주어진 value이다.</p>

<p>Linear regression에서는 이 값이 exact한 값으로 나왔지만, nonlinear한 neural network에서는 $\alpha$가 변화함에 따라 $\mathbf{H}$도 변화한다. 따라서 위와 같은 결과는 $\lambda_i$를 $\alpha$로 미분한 항을 무시한 것으로 봐야한다.</p>

<p>또한, 최적의 $\beta$는 3.5절에서 처럼</p>

\[\cfrac{1}{\beta} = \cfrac{1}{N - \gamma} \sum_{n = 1}^{N}\{ y(\mathbf{x}_n,\mathbf{w}_{MAP}) - t_n \}^2\]

<p>로 주어진다.</p>

<p>Linear model에서 처럼 이제 alternating optimization을 통해 최적의 hyperparameter를 찾을 수 있지만, neural network의 nonlinearity로 인해 $\mathbf{w}$의 첫 initialization에 따라 최적의 hyperparameter가 달라질 수 있다.</p>

<p>다른 개수의 hidden units를 가진 model들 간의 비교와 같이 모델 간 비교를 위해서는 model evidence 
$p(\mathbf{D}|\alpha,\beta)$
를 비교할 수 있다. 하지만 5.1.1절에서 보았듯 $M$을 hidden units의 개수라고 할 때 two-layer network는 
$M!2^{M}$
만큼의 equivalent modes가 존재하기 때문에 evidence에 
$M!2_{M}$
만큼의 값을 곱해줘야 정확한 비교를 할 수 있을 것이다.</p>

<h3 id="573-bayesian-neural-networks-for-classification">5.7.3 Bayesian neural networks for classification</h3>

<p>이제 two-class classifiction을 위한 neural network에 Bayesian treatment를 적용하는 방법을 살펴보고자 한다. Log likelihood function은</p>

\[ln \ p(\mathbf{D}|\mathbf{w}) = \sum_{n = 1}^{N}\{ t_n ln \ y_n + (1 - t_n) ln(1 - y_n) \}\]

<p>으로 주어질 것이고, $\mathbf{w}$에 대한 prior는 regression 때와 동일하게 주어졌다고 가정하자. 이제 5.7.2절에서와 동일한 방식으로 Bayesian neural network를 construct 할 수 있다. 먼저 $\mathbf{w}_{MAP}$를 구한 뒤, Hessian $\mathbf{H}$를 구하자. 이후에는 동일하게 Laplace approximation을 통해 posterior에 대한 Gaussian approximation이 가능하다.</p>

<p>Hyperparameter $\alpha$에 대한 optimization을 위해 다시 marginal likelihood를 Laplace approximation을 통해</p>

\[ln \ p(\mathbf{D}|\alpha) \simeq -E(\mathbf{w}_{MAP}) - \cfrac{1}{2} ln \ |\mathbf{A}| + \cfrac{W}{2} ln \ \alpha + \text{const}\]

<p>where</p>

\[E(\mathbf{w}) = - ln \ p(\mathbf{D}|\mathbf{w}) + \cfrac{\alpha}{2}\mathbf{w}^{T}\mathbf{w}\]

<p>으로 구할 수 있다. 이를 $\alpha$에 대해 maximize 하면 다시</p>

\[\alpha = \cfrac{\gamma}{\mathbf{w}_{MAP}^{T}\mathbf{w}_{MAP}}\]

<p>로 구해짐을 알 수 있다.</p>

<p>이제 마지막으로 predictive distribution을 구해야한다. 여기서도 역시 적분이 intractable하기 때문에 approximation을 사용해야 한다. 가장 간단한 방법은 posterior distribution이 굉장히 narrow 하다고 가정하고,</p>

\[p(t|\mathbf{x},\mathbf{D}) \simeq p(t|\mathbf{x},\mathbf{w}_{MAP})\]

<p>로 두는 것이다.</p>

<p>더 좋은 방법은 posterior distribution의 variance를 감안하는 것인데, logistic activation function으로 인해 regression에서 처럼 network output을 linear하게 approximate할 수는 없다. 이에 output unit activation에 대한 linear approximation</p>

\[a(\mathbf{x},\mathbf{w}) \simeq a(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{b}^{T}(\mathbf{w} - \mathbf{w}_{MAP})\]

<p>where</p>

\[\mathbf{b} \equiv \bigtriangledown a(\mathbf{x},\mathbf{w}_{MAP})\]

<p>을 대신 이용하자.</p>

<p>이제 posterior distribution도 Gaussian approximate 되었고, $a$가 $\mathbf{w}$에 대한 linear function이기 때문에 4.5.2절의 결과를 통해</p>

\[p(a|\mathbf{x},\mathbf{D}) = \int \delta(a - a(\mathbf{x},\mathbf{w}_{MAP}) - \mathbf{b}^{T}(\mathbf{x})(\mathbf{w}- \mathbf{w}_{MAP}))q(\mathbf{w|\mathbf{D}})d\mathbf{w}\]

<p>로 주어지며 이 분포가 평균을 $a(\mathbf{x},\mathbf{w}_{MAP})$로 분산을</p>

\[\sigma_{a}^{2}(\mathbf{x}) = \mathbf{b}^{T}(\mathbf{x})\mathbf{A}^{-1}\mathbf{b}(\mathbf{x})\]

<p>로 갖는 Gaussian distribution 이라는 것을 알 수 있다.</p>

<p>마지막으로 predictive distribution를</p>

\[p(t = 1| \mathbf{x},\mathbf{D}) = \int \sigma(a) p (a|\mathbf{x},\mathbf{D})da\]

<p>로 구할 수 있다. 하지만 Gaussian 과 logistic sigmoid간의 convolution은 intractable 하기 때문에 다시 4.5.2절의 approximation을 이용해</p>

\[p(t = 1| \mathbf{x},\mathbf{D}) = \sigma \big( \kappa(\sigma_{a}^2)\mathbf{b}^{T}\mathbf{w}_{MAP} \big)\]

<p>where</p>

\[\kappa(\sigma^2) = (1 + \pi\sigma^2/8)^{-1/2}\]

<p>로 구할 수 있다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[5.5.5 Training with transformed data]]></summary></entry><entry><title type="html">PRML 스터디 Chap.5.4</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-4/" rel="alternate" type="text/html" title="PRML 스터디 Chap.5.4" /><published>2022-02-17T00:00:00+09:00</published><updated>2022-02-17T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-4</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-4/"><![CDATA[<h2 id="54-the-hessian-matrix">5.4 The Hessian Matrix</h2>

<p>지금까지는 1차 미분값 (gradient)를 구하기 위해 backpropagation을 쓰는 방법을 공부했지만, backpropagation을 이용하여 2차 미분값</p>

\[\cfrac{\partial^2 E}{\partial w_{ji}\partial w_{lk}}\]

<p>을 구할 수 도 있다. 이 때, 2차 미분 값을 모아둔 matrix를 Hessian Matrix라고 부르는데, Hessian은 다음과 같은 역할로 사용된다.</p>

<ol>
  <li>다양한 비선형 최적화 알고리즘은 2차 미분값의 특성에 기반을 두고 있다.</li>
  <li>Train data에 변화가 생겼을 때 빠르게 re-train 하는데 2차 미분값이 사용된다.</li>
  <li>Hessian의 inverse를 통해 weight의 중요도를 판단할 수 있다.</li>
  <li>Bayesian nueral network에서 Laplace approximation을 하는데 사용된다.</li>
</ol>

<p>Hessian은 approximation을 통해서 구하기도 하고, backpropagation을 통해 exact value를 구할 수도 있다. 다만, 전체 $W$개의 parameter가 존재한다고 할 때, Hessian의 차원은 $W \times W$ 이기 때문에 efficient evaluation scale은 $O(W^2)$이다.</p>

<h3 id="541-diagonal-approximation">5.4.1 Diagonal approximation</h3>

<p>많은 경우 Hessian 그 자체보다 Hessian의 inverse가 필요하다. 따라서 Hessian의 diagonal을 approximate해서 off-diagonal을 0으로 두고 inverse를 쉽게 구하는 경우가 있다. 당연히 대부분의 Hessian은 diagonal matrix가 아니기 때문에 사용시 주의를 기울여야 한다. Hessian의 diagonal element는</p>

\[\cfrac{\partial^2 E_n}{\partial w_{ji}^2} = \cfrac{\partial E_n}{\partial a_j^2}z_i^2\]

<p>로 주어지는데, 앞서 봤던 chain rule을 이용하면</p>

\[\cfrac{\partial E_n}{\partial a_j^2} = h'(a_j)^2 \sum_{k} \sum_{k'}w_{kj}w_{k'j}\cfrac{\partial^2 E_n}{\partial a_k \partial a_{k'}} + h''(a_j) \sum_{k} w_{kj} \cfrac{\partial E_n}{\partial a_k}\]

<p>임을 알 수 있다. 이제 2차 미분 term에서 off-diagonal term을 지우면</p>

\[\cfrac{\partial E_n}{\partial a_j^2} = h'(a_j)^2 \sum_{k}w_{kj}^2\cfrac{\partial^2 E_n}{\partial a_k^2} + h''(a_j) \sum_{k} w_{kj} \cfrac{\partial E_n}{\partial a_k}\]

<p>을 구할 수 있다. 이러한 diagonal approximation의 cost는 $O(W)$로, full Hessian의 $O(W^2)$ 보다 훨씬 적은 cost가 든다. 물론, odff-diagonal term을 지우지 않고 approximate할 수 있지만 그러면 $O(W)$ scale이 아니게 된다.</p>

<h3 id="542-outer-product-approximation">5.4.2 Outer product approximation</h3>

<p>Single output regression 문제를 생각하면 Hessian  $\mathbf{H}$는</p>

\[\mathbf{H} = \bigtriangledown \bigtriangledown E = \sum_{n=1}^{N} \bigtriangledown y_n \bigtriangledown y_n + \sum_{n=1}^{N} (y_n - t_n) \bigtriangledown \bigtriangledown y_n\]

<p>으로 주어진다. 이때, optimal function은  target data의 conditional average를 output으로 주기 때문에 뒤에 
<span>$y_n - t_n$</span>
은 zero mean을 가지는 random variable이 된다. 2차 미분값과 uncorrelated 되었다고 가정하면 second term 전체는 sum을 거치면서 0으로 approximate 될 것이다.</p>

<p>이렇게</p>

\[\mathbf{H} \backsimeq \sum_{n=1}^N \mathbf{b}_n\mathbf{b}_n^T\]

<p>where <span>$\mathbf{b}_n = \bigtriangledown y_n = \bigtriangledown a_n$</span></p>

<p>형태의 approximation을 outer product approximation이라 부른다. 1차 미분값 만을 이용하여 approximation을 하기 때문에 전체 $O(W^2)$의 cost가 든다. 물론, 실제로는 second term을 무시하기 힘들기 때문에 가정처럼 잘 train 된 network에 대해서만 유의미한 approximation이다.</p>

<p>Cross-entropy error function에 logistic sigmoid output-uinit activation function을 사용하는 경우</p>

\[\mathbf{H} \backsimeq \sum_{n=1}^N y_n(1-y_n) \mathbf{b}_n\mathbf{b}_n^T\]

<p>으로 approximate 할 수 있으며 softmax의 경우에도 형태에 맞춰 approximate 할 수 있다.</p>

<h3 id="543-inverse-hessian">5.4.3 Inverse Hessian</h3>

<p>Outer approximation을 통해 Hessian의 inverse를 쉽게 approximate할 수 있다. Outer approximation을</p>

\[\mathbf{H}_N = \sum_{n=1}^{N} \mathbf{b}_n\mathbf{b}_n^T\]

<p>로 notate하자. 현재까지 $L$ data points를 통해 Hessian matrix를 approximate 하고 그 inverse를 구했다고 하자. 이때 $L+1$th data point를 추가하면</p>

\[\mathbf{H}_{L+1} = \mathbf{H}_{L} + \mathbf{b}_{L+1}\mathbf{b}_{L+1}^T\]

<p>로 쓸 수 있다. 이때, Woodbury identity를 이용하면</p>

\[\mathbf{H}_{L+1}^{-1} = \mathbf{H}_{L}^{-1} - \cfrac{\mathbf{H}_{L}^{-1}\mathbf{b}_{L+1} \mathbf{b}_{L+1}^T \mathbf{H}_{L}^{-1}}{1+ \mathbf{b}_{L+1}^T \mathbf{H}_{L}^{-1} \mathbf{b}_{L+1}}\]

<p>를 구할 수 있다. 이러한 방법을 통해 $L+1$이 N이 될 때까지 sequential하게 구하면 Hessian matrix의 inverse를 쉽게 approximate할 수 있다. 가장 첫 $\mathbf{H}_0$은 보통 $\alpha \mathbf{I}$로 두기 때문에 실질적으로는 
$\mathbf{H} + \alpha \mathbf{I}$의 inverse를 구하는 형태가 된다.</p>

<h3 id="544-finite-differences">5.4.4 Finite differences</h3>

<p>Hessian 역시 finite differences를 통해 구할 수 있는데,</p>

\[\cfrac{\partial^2 E}{\partial w_{ji} \partial w_{lk}} = \cfrac{1}{4 \epsilon^2}\{E(w_{ji} + \epsilon, \ w_{lk} + \epsilon ) - E(w_{ji} + \epsilon, \ w_{lk} - \epsilon ) \\ - E(w_{ji} - \epsilon, \ w_{lk} + \epsilon) + E(w_{ji} - \epsilon, \ w_{lk} - \epsilon ) \} + O(\epsilon^2)\]

<p>의 형태가 된다. Hessian에는 $W^2$의 element가 있고, 하나의 evaluation은 $W$ 만큼의 cost가 들기 때문에 총 $O(W^3)$의 ocst가 들지만 여전히 backpropagation implementation의 check를 위해 사용된다.</p>

<p>1차 미분값에 central difference를 이용해 numerical differentiation을 더 효울적으로 할 수 있는데,</p>

\[\cfrac{\partial^2 E}{\partial w_{ji} \partial w_{lk}} = \cfrac{1}{2\epsilon} \bigg\{ \cfrac{\partial E}{\partial w_{ji}}(w_{lk} + \epsilon) - \cfrac{\partial E}{\partial w_{ji}}(w_{lk} - \epsilon)  \bigg\} + O(\epsilon^2)\]

<p>의 형태가 되며 이때는 $O(W^2)$ 만큼의 cost가 드는 것을 확인할 수 있다.</p>

<h3 id="545-exact-evaluation-of-the-hessian">5.4.5 Exact evaluation of the Hessian</h3>

<p>현재까지는 Hessian 혹은 그 inverse를 approximate하는 방법을 살펴보았지만, 실제로 Hessian은 backpropagation을 통해 excat evaluation이 가능하며 그 cost는 $O(W^2)$ scale이다.</p>

<p>여기서는 예시로 input ($i,i’$ index), 하나의 hidden layer ($j, j’$ index), 그리고 output ($k,k’$ index)로 이루어진 network를 생각하겠다. 먼저</p>

\[\delta_k = \cfrac{\partial E_n}{\partial a_k}, \; M_{kk'} \equiv \cfrac{\partial^2 E_n}{\partial a_k \partial a_{k'}}\]

<p>를 정의하자.  이때 Hessian matrix는 3개의 block으로 구성되는 것으로 생각할 수 있는데,</p>

<ol>
  <li>Second layer에서의 weights에 대한 2차 미분</li>
</ol>

\[\cfrac{\partial^2 E_n}{\partial w_{kj}^{(2)} \partial w_{k'j'}^{(2)}} = z_j z_{j'}M_{kk'}\]

<ol>
  <li>First layer에서의 weights에 대한 2차 미분</li>
</ol>

\[\cfrac{\partial^2 E_n}{\partial w_{ji}^{(1)} \partial w_{j'i'}^{(1)}} = x_i x_{i'} h''(a_{j'})I_{jj'}\sum_{k} w_{kj'}^{(2)}\delta_{k} \\ + x_i x_{i'}h'(a_{j'})h'(a_j)\sum_{k} \sum_{k'} w_{k'j'}^{(2)} w_{kj}^{(2)}M_{kk'}\]

<ol>
  <li>각 layer에서 weight 한번씩</li>
</ol>

\[\cfrac{\partial^2 E_n}{\partial w_{ki}^{(2)}\partial w_{kj'}^{(2)}} = x_i h'(a_{j'}) \bigg\{ \delta_k I_{jj'} + z_j \sum_{k'} w_{k'j'}^{(2)} H_{kk'} \bigg\}\]

<p>로 각각 구해진다.</p>

<h3 id="546-fast-multiplication-by-the-hessian">5.4.6 Fast multiplication by the Hessian</h3>

<p>Hessian을 사용하는 대부분의 case는 $\mathbf{v}^T\mathbf{H}$ 형태의 vector를 product한 경우이다. 이때 $\mathbf{v}^T\mathbf{H}$는 $O(W)$ scale이기 때문에 이를 바로 계산하는 것이 더 효율적일 것이다. 이를 위해</p>

\[\mathbf{v}^T\mathbf{H} = \mathbf{v}^T \bigtriangledown (\bigtriangledown E)\]

<p>에서</p>

\[\mathcal{R}\{\cdot \} \equiv \mathbf{v}^T \bigtriangledown (\cdot)\]

<p>notation을 정의하자. 예를 들어</p>

\[\mathcal{R}\{\ \mathbf{w} \} = \mathbf{v}\]

<p>가 될 것이다.</p>

<p>다시 two-layer network에 linear output units, sum-of-square error function을 사용하는 경우를 예로 들어보자. Forward propagation의 경우</p>

\[\begin{aligned}
a_j &amp;= \sum_i w_{ji}x_i \\
z_j &amp;= h(a_j) \\
y_k &amp;= \sum_j w_{kj} z_j
\end{aligned}\]

<p>으로 정의했었는데, 이제 $\mathcal{R}{\cdot}$ operator를 사용하여</p>

\[\begin{aligned}
\mathcal{R}\{a_j\} &amp;= \sum_i v_{ji}x_i \\
\mathcal{R}\{z_j\} &amp;= h'(a_j)\mathcal{R}\{a_j\} \\
\mathcal{R}\{y_k\} &amp;= \sum_j w_{kj} \mathcal{R}\{z_j\} + \sum_j v_{kj}z_j
\end{aligned}\]

<p>를 구할 수 있다. (여기서 $v_{ji}$는 weight $w_{ji}$에 대응하는 element)</p>

<p>이제 bacpropagation으로 돌아가면</p>

\[\begin{aligned}
\delta_k &amp;= y_k - t_k \\
\delta_j &amp;= h'(a_j) \sum_k w_{kj}\delta_k
\end{aligned}\]

<p>임을 알고 있었다. 여기서도 $\mathcal{R}{\cdot}$ operator를 사용하여</p>

\[\begin{aligned}
\mathcal{R}\{\delta_k\} &amp;= \mathcal{R}\{y_k\} \\
\mathcal{R}\{\delta_j\} &amp;= h''(a_j)\mathcal{R}\{a_j\}\sum_{k} w_{kj}\delta_k \\
&amp;+ h'(a_j)\sum_{k} v_{kj}\delta_k + h'(a_j)\sum_{k} w_{kj}\mathcal{R}\{\delta_k\}
\end{aligned}\]

<p>를 구할 수 있다.</p>

<p>마지막으로, 1차 미분값</p>

\[\begin{aligned}

\cfrac{\partial E}{\partial w_{kj}} &amp;= \delta_k z_j \\

\cfrac{\partial E}{\partial w_{ji}} &amp;= \delta_j x_i

\end{aligned}\]

<p>에  $\mathcal{R}{\cdot}$ operator를 사용하여 vector $\mathbf{v}^T\mathbf{H}$의 원소에 대한 expression을 구할 수 있다.</p>

\[\begin{aligned}

\mathcal{R}\bigg\{ \cfrac{\partial E}{\partial w_{kj}} \bigg\} &amp;=  \mathcal{R}\{\delta_k\} z_j + \delta_k \mathcal{R}\{z_j\} \\


\mathcal{R}\bigg\{ \cfrac{\partial E}{\partial w_{ji}}\bigg\} &amp;= x_{i}\mathcal{R}\{\delta_j\}

\end{aligned}\]

<p>이때 $\mathbf{v}$에 unit vector를 넣어 Hessian의 element도 구할 수 있다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[5.4 The Hessian Matrix]]></summary></entry><entry><title type="html">PRML 스터디 Chap.5.2-3</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-2-3/" rel="alternate" type="text/html" title="PRML 스터디 Chap.5.2-3" /><published>2022-02-06T00:00:00+09:00</published><updated>2022-02-06T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-2-3</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-5-2-3/"><![CDATA[<h3 id="522-local-quadratic-approximation">5.2.2 Local quadratic approximation</h3>

<p>Error function $E(\mathbf{w})$에 대해 point $\hat{\mathbf{w}}$ 를 기준으로 Taylor expansion을 하면</p>

\[E(\mathbf{w}) \simeq E(\hat{\mathbf{w}}) + (\mathbf{w}-\hat{\mathbf{w}})^{T}\mathbf{b} + \cfrac{1}{2}(\mathbf{w} - \hat{\mathbf{w}})^{T}\mathbf{H}(\mathbf{w} - \hat{\mathbf{w}})\]

<p>where</p>

\[\mathbf{b} \equiv \bigtriangledown E|_{\mathbf{w} = \hat{\mathbf{w}}}\]

<p>and</p>

\[\mathbf{H} = \bigtriangledown\bigtriangledown E|_{\mathbf{w} = \hat{\mathbf{w}}}\]

<p>으로 정리된다. 여기서 gradient에 대한 local approximation을 유도하면</p>

\[\bigtriangledown E \simeq \mathbf{b} + \mathbf{H}(\mathbf{w} - \hat{\mathbf{w}})\]

<p>를 구할 수 있다. 이제 error function의 minimum point <span> $\mathbf{w}^{*}$ </span>를 기준으로 생각해보자. <span> $\mathbf{w}^{*}$ </span>에서는 $\bigtriangledown E = 0$ 이므로,</p>

\[E(\mathbf{w}) = E(\mathbf{w}^*) + \cfrac{1}{2}(\mathbf{w} - \mathbf{w}^*)\mathbf{H}(\mathbf{w} - \mathbf{w}^*)\]

<p>으로 정리할 수 있다. 수식의 의미를 기하학적으로 이해하기 위해 $\mathbf{H}$에 대해 eigendecomposition을 하면</p>

\[\mathbf{H}\mathbf{u}_i = \lambda_{i}\mathbf{u}_i\]

<p>으로 쓸 수 있다. 여기서 eigenvector는 complete orthonormal set 이므로,</p>

\[(\mathbf{w} - \mathbf{w}^*) = \sum_{i}\alpha_i\mathbf{u}_i\]

<p>로 나타낼 수 있다. 이는 기존의 coordinate system을 point $\mathbf{w}^*$를 origin으로 하고 eigenvectors를 축으로 하는 coordinate system으로 transform 시킨 것으로 이해할 수 있다. 이제 error function은</p>

\[E(\mathbf{w}) = E(\mathbf{w}^*) + \cfrac{1}{2}\sum_{i}\lambda_i\alpha_i^{2}\]

<p>의 형태가 된다. 이를 그림으로 나타내면</p>

<p><img src="/assets/img/2022-02-06-prml-스터디-chap-5-2-3/Fig.5.6.png" alt="" title="Figure 5.6" /></p>

<p>의 형태로 이해할 수 있다.</p>

<p>또한, one-dimensional space에서 stationary point <span> $\mathbf{w}^*$ </span> 가 mimimum이 되려면 2차 미분 값이 양수여야 하듯이, D-dimensional space에서는 Hessian Matrix가 positive definite (eigenvalue가 모두 양수)가 되어야 한다. 그러므로 minimum point <span> $\mathbf{w}^*$ </span>에 대해 항상 이러한 geometric interpretation이 가능한 것을 알 수 있다.</p>

<h3 id="523-use-of-gradient-information">5.2.3 Use of gradient information</h3>

<p>이후 5.3절 에서는 backpropagation procedure을 통해 gradient를 빠르게 계산할 수 있음을 보일 것이다. 이번 절에서는 왜 gradient information을 사용하는 것이 error function의 minima를 찾는 데에 효율적인지 살펴보자.</p>

<p>이전 5.2.2절에서 살펴본 local quadratic approximation에 따르면, error function은 $\mathbf{b}, \ \mathbf{H}$에 depend 하는데, 해당 term들은 총 $W(W+3)/2$ 만큼의 independent elements를 가지고 있다 ($W$는 weight의 dimension). 따라서 quadratic approximation의 mimimum의 location은 $O(W^2)$ 개의 parameter를 통해야 알 수 있다는 것이며, minimum을 찾기 위해서는 $O(W^2)$ 만큼의 정보를 모아야한다는 것을 알 수 있다. 따라서 gradient information을 사용하지 않으면 function evaluation을 $O(W^2)$번 해야하는데, 각 evaluation의 cost는 $O(W)$이기 때문에 총 $O(W^3)$ 만큼의 cost가 든다는 것을 알 수 있다.</p>

<p>반면에 gradient를 사용하는 경우를 생각해보자. Gradient evaluation 한 번에 $W$ 만큼의 정보가 생기므로 evaluation을 $O(W)$ 만큼 하면 minimum을 찾을 수 있다. 이때 backpropagation을 이용하면 gradient evaluation의 cost는 $O(W)$이기 때문에 총 $O(W^2)$ 만큼의 cost 만으로 minima를 찾을 수 있다는 것을 알 수 있다. Cubic time complexity를 quadratic time complexity로 줄인 것이다.</p>

<h3 id="524-gradient-descent-optimization">5.2.4 Gradient descent optimization</h3>

<p>Gradient information을 통해 weight를 update 하는 가장 쉬운 방법은 gradient descent를 통해</p>

\[\mathbf{w}^{(t+1)} = \mathbf{w}^{(t)} - \eta \bigtriangledown E(\mathbf{w}^{(t)})\]

<p>iterative하게 minimum을 찾아가는 것이다. 이때 전체 train set을 다 쓰게 되며, 이를 batch method라고 한다. 하지만 이런 batch method는 intuitive 하지만 성능이 좋지 않으며, 이를 개선한 conjugate gradient나 quasi-newton method 등이 개발되었다. 해당 알고리즘들은 gradient descent와 다르게 local 혹은 global minima에 다다를 때 까지 항상 error function이 decrease 한다는 특성을 가진다.</p>

<p>하지만 large data set을 이용하기 위해선 on-line version of gradient descent가 필요하다. Error function은 data point에서의 maximum likelihood에 기반하기 때문에,</p>

\[E(\mathbf{w}) = \sum_{n = 1}^{N} E_n(\mathbf{w})\]

<p>으로 나타낼 수 있다. 따라서 on-line gradient descent 혹은 stochastic gradient descent는 한번에 data point 하나를 이용하여</p>

\[\mathbf{w}^{(t+1)} = \mathbf{w}^{(t)} - \eta \bigtriangledown E_n(\mathbf{w}^{(t)})\]

<p>weight를 update 한다. Data point의 선택은 sequential 하게 혹은 random으로 repeat 된다. 또한, gradient descent와 stochastic descent의 중간 지점격으로 일정 portion의 data point를 묶어서 계산하는 경우도 존재한다.</p>

<p>이러한 stochastic descent의 장점은</p>

<ol>
  <li>계산이 더 효율적이다.</li>
  <li>Data point 전체에 대한 stationary point와 하나 하나에 대한 stationary point는 다르기 때문에 local minima를 빠져나올 가능성이 더 높다.</li>
</ol>

<p>로 정리할 수 있다.</p>

<h2 id="53-error-backpropagation">5.3 Error Backpropagation</h2>

<p>Backpropagation이란 gradient 계산을 위해 정보를 network의 forward 그리고 다시 backward에 alternative 하게 전달하는 방법을 의미한다. 먼저 network의 training phase를 좀 더 자세하게 살펴보자. 대부분의 training algorithm은 weight의 sequential update를 통해 error function를 iterative 하게 줄여나간다. 각 iteration은 2개의 distinct한 stage로 나눌 수 있는데, 첫번째는 error function의 derivative w.r.t. weights 가 계산되는 stage이다. Backpropagation은 이러한 derivative 계산을 효율적으로 하는데 큰 도움을 주는 methodology 이다. 두번째는 해당 derivative를 이용해 weight를 update 하는 stage이다. 이를 위해서 이전에 다뤘던 gradient descent와 같은 방법을 사용할 수 있다. 이 2 stage는 서로 독립적인 관계로, 양쪽에서 쓰이는 methodology는 neural network 외에도 다른 모델에 독립적으로 사용될 수 있다.</p>

<h3 id="531-evaluation-of-error-function-derivatives">5.3.1 Evaluation of error-function derivatives</h3>

<p>이제 일반적으로 backpropagation이 어떻게 이루어지는지 살펴보자. 여기서는 전체 data point가 아닌 하나의 data point에 대한 $\bigtriangledown E_n(\mathbf{w})$ 계산만 다룰 것이다.</p>

<p>먼저 hidden layer 가 하나인 neural network를 생각해보자. Hidden layer의 unit $z_j$는 input $z_i$ (hidden layer가 많아지면 input이 아닌 그 전 hidden unit으로 생각)와 activation function $h(\cdot)$를 이용하여</p>

\[z_j = h(a_j)\]

<p>where $a_j = \sum_{i}w_{ji}z_i$</p>

<p>로 나타낼 수 있다. 여기서 $w_{ji}$는 $z_i$를 $z_j$로 연결시켜주는 weight이다. 이후 output layer은 다시 $z_j$와 link function을 이용해 output unit $z_k$를 계산할 것이다. 이렇게 neural network의 구조를 통해 input vector를 이용해 output을 계산하는 과정을 forward propagation 이라 부른다.</p>

<p>이제 weight $w_{ji}$에 대한 $E_n$의 derivative를 구하는 과정을 살펴보자. $E_n$은 $a_j$를 통해서만 $w_{ji}$에 depend 하기 때문에 chain rule에 따라</p>

\[\cfrac{\partial E_n}{\partial w_{ji}} = \cfrac{\partial E_n}{\partial a_j}\cfrac{\partial a_j}{\partial w_{ji}}\]

<p>로 계산된다. Error term</p>

\[\delta_j \equiv \cfrac{\partial E_n}{\partial a_j}\]

<p>를 정의하고,</p>

\[\cfrac{\partial a_j}{\partial w_{ji}} = z_i\]

<p>임을 이용하여</p>

\[\cfrac{\partial E_n}{\partial w_{ji}} = \delta_j z_i\]

<p>를 계산할 수 있다. 이는 weight의 output end에 있는 error $\delta$에 weight의 input end에 있는 $z$를 곱한 형태로 이전의 linear model에서도 많이 볼 수 있던 형태이다. 이제 $\delta_j$를 계산해보자.</p>

<p>다시 chain rule을 이용하면</p>

\[\delta_j \equiv \cfrac{\partial E_n}{\partial a_j} = \sum_k \cfrac{\partial E_n}{\partial a_k}\cfrac{\partial a_k}{\partial a_j}\]

<p>임을 알 수 있고, 이전 Chap.4에서 다뤘듯 canonical link function을 이용하는 경우 output unit에 대한 error $\delta_k$는</p>

\[\delta_k \equiv \cfrac{\partial E_n}{\partial a_k} = y_k - t_k\]

<p>으로 계산된다. 따라서 최종 $\delta_j$의 값은</p>

\[\delta_j = h'(a_j)\sum_k w_{kj}\delta_k\]

<p>로 나타내진다. 이는 특정 hidden layer의 error term은 다음 layer의 error term에 대한 정보를 backward 전달하여 구해질 수 있다는 의미로 왜 이 방법론이 backpropagation으로 불리는지 알 수 있는 대목이다. 이러한 방법을 통해 모든 형태의 neural network에 대한 derivative calculation을 할 수 있다.</p>

<p>Batch method에 대해서는 이렇게 data point 하나에 대해 구한 derivative를 cumulative 하게 더해 구할 수 있다.</p>

\[\cfrac{\partial E}{\partial w_{ji}} = \sum_n \cfrac{\partial E_n}{\partial w_{ji}}\]

<h3 id="532-a-simple-example">5.3.2 A simple example</h3>

<p>이제 실제 예시를 통해 5.3.1 절의 결과를 살펴보자. 동일하게 hidden layer가 하나인 형태의 neural network에서 error function은 sum-of-square error를 (link function이 identity function) activation function으로 $h(\cdot) = tanh(\cdot)$을 사용한다고 가정하자.</p>

<p>이때</p>

\[h'(a) = 1 - h(a)^2 \\
\delta_k = y_k - t_k\]

<p>임을 이용하여</p>

\[\delta_j = (1 - z_j^2)\sum_{k= 1}^{K}w_{kj}\delta_k\]

<p>를 계산할 수 있고, 최종적으로</p>

\[\cfrac{\partial E_n}{\partial w_{ji}} = \delta_j z_i, \ \ \ \ \cfrac{\partial E_n}{\partial w_{kj}} = \delta_k z_j\]

<p>임을 알 수 있다.</p>

<h3 id="533-efficiency-of-backpropagation">5.3.3 Efficiency of backpropagation</h3>

<p>Backpropagation의 가장 큰 이점 중 하나는 computational efficiency 이다. Error function의 single evaluation은 $O(W)$ 만큼의 time complexity를 가진다.</p>

<p>Backpropagation을 대체하는 방법으로 finite differences를 사용할 수 있는데, 이는 derivative를 approximate 하는 방법으로</p>

\[\cfrac{\partial E_n}{\partial w_{ji}} = \cfrac{E_n(w_{ji} + \epsilon) - E_n(w_{ji})}{\epsilon} + O(\epsilon)\]

<p>혹은 symmetrical central differences (더 정확하지만 computational step이 2배)</p>

\[\cfrac{\partial E_n}{\partial w_{ji}} = \cfrac{E_n(w_{ji} + \epsilon) - E_n(w_{ji}- \epsilon)}{2\epsilon} + O(\epsilon^2)\]

<p>를 이용할 수 있다. 하지만 finite difference는 forward propagation을 하는데 $O(W)$ step, 그리고 weight 하나 하나에 대해서 approximate를 해야하기 때문에 총 $O(W^2)$ time complexity를 가지기 때문에 back propagation의 $O(W)$에 비해 훨씬 많은 시간이 걸린다는 것을 알 수 있다. (하지만 finite difference 방법은 backpropagation이 정확하게 implement 되었는지 확인하기 위한 용도로 자주 사용된다.)</p>

<h3 id="534-the-jacobian-matrix">5.3.4 The Jacobian matrix</h3>

<p>Backpropagationd은 weight에 대한 derivative 외에도 다른 derivative를 구하는 데에도 사용될 수 있다. 이번 절에서는 output의 input에 대한 미분으로 이루어진 Jacobian matrix</p>

\[J_{ki} \equiv \cfrac{\partial y_k}{\partial x_i}\]

<p>를 다룰 것이다. Jacobian matrix는 Figure 5.8 처럼 여러 개의 module로 이루어진 system에서 유용하게 사용된다.</p>

<p><img src="/assets/img/2022-02-06-prml-스터디-chap-5-2-3/Fig%205.8.png" alt="" /></p>

<p>Figure 5.8에서의 paramter $w$에 대해 error function E를 minimize 한다고 생각해보자. 그럼 derivative는</p>

\[\cfrac{\partial E}{\partial w} = \sum_{k,j}\cfrac{\partial E}{\partial y_k}\cfrac{\partial y_k}{\partial z_j}\cfrac{\partial z_j}{\partial w}\]

<p>로 구할 수 있으며 Jacobian은 중간 term으로 나타난다.</p>

<p>Jacobian은 input variable의 change에 대한 output variable의 local sensitivity를 의미하기 때문에 어떤 known error $\bigtriangleup x_i$의 output에 대한 contribution을 계산하는 데에도 사용된다.</p>

\[\bigtriangleup y_k \simeq \sum_i \cfrac{\partial y_k}{\partial x_i} \bigtriangleup x_i\]

<p>기본적으로 network mapping이 nonlinear 하기 때문에 Jacobian matrix의 element는 constant 값이 아닌 input에 depend 하게 된다. 따라서 위 식은 input의 작은 변화에만 유의미하며, 새로운 input vector에 대해서는 새로 re-evaluated 되어야 한다.</p>

<p>Jacobian matrix는 이전에 weight에 대한 derivative를 backpropagation을 통해 구했던 것 처럼 backpropagation을 통해 구할 수 있다.</p>

\[J_{ki} = \cfrac{\partial y_k}{\partial x_i} = \sum_j\cfrac{\partial y_k}{\partial a_j}\cfrac{\partial a_j}{\partial x_i} = \sum_j w_{ji} \cfrac{\partial y_k}{\partial a_j}\]

<p>이제 $\cfrac{\partial y_k}{\partial a_j}$ 에 대한 backpropagation을 계산하면,</p>

\[\cfrac{\partial y_k}{\partial a_j} = \sum_l \cfrac{\partial y_k}{\partial a_l} \cfrac{\partial a_l}{\partial a_j} = h'(a_j) \sum_l w_{lj} \cfrac{\partial y_k}{\partial a_l}\]

<p>가 된다. 이때, link function으로 sigmoid를 사용하면</p>

\[\cfrac{\partial y_k}{\partial a_j} = \delta_{kj}\sigma '(a_j)\]

<p>softmax를 사용하면</p>

\[\cfrac{\partial y_k}{\partial a_j} = \delta_{kj}y_k - y_ky_j\]

<p>로 계산할 수 있다.</p>

<p>Jacobian matrix에 대한 backpropagation implementation도 numerical differentiation을 통해 제대로 implement 되었는지 check 할 수 있다.</p>

\[\cfrac{\partial y_k}{\partial x_i} = \cfrac{y_k(x_i + \epsilon) - y_k(x_i - \epsilon)}{2\epsilon} + O(\epsilon^2)\]]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[5.2.2 Local quadratic approximation]]></summary></entry><entry><title type="html">PRML 스터디 Chap.4.3</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-3/" rel="alternate" type="text/html" title="PRML 스터디 Chap.4.3" /><published>2022-01-27T00:00:00+09:00</published><updated>2022-01-27T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-3</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-3/"><![CDATA[<h2 id="43-probabilistic-discriminative-model">4.3 Probabilistic Discriminative Model</h2>

<p>4.2절에서는 
<span>$p(\mathbf{x}|C_k)$ </span>
에 대한 분포 가정을 통해 Bayes Thm을 이용하여 posterior 
<span>$p(C_k|\mathbf{x})$ </span>
를 구하는 과정을 설명했다. 그 결과 
<span>$p(C_k|\mathbf{x})$</span>
가 
$\mathbf{x}$
에 대한 linear form으로 나타나는 것을 확인할 수 있었다. 4.3절에서는 거기서 착안하여, 
<span>$p(\mathbf{x}|C_k)$</span>
에 대한 분포가정 없이 Generalized Linear Model을 이용해 Probabilistic Discriminative Model을 생성하고 parameter를 구하는 방법을 소개한다.</p>

<h3 id="431-fixed-basis-functions">4.3.1 Fixed basis functions</h3>

<p>4장 에서는 지금까지 input vector $\mathbf{x}$의 공간에서 classification model들을 생각했지만, 3장에서 다룬 것처럼 basis function $\phi(\mathbf{x})$를 이용하여 non-linear한 transform을 거친 후 feature space에서 classification model을 생각할 수 있다. 이를 통해 original input space에서 linear classification이 불가능한 문제도 feature space에서 linear 하게 해결할 수 있기 때문에 classification에서도 매우 중요한 방법이다. 물론, 이러한 fixed basis function 모델은 나름대로의 한계점들이 존재하기 때문에, 이후 chapter에서 basis function을 데이터에 맞춰 adapt하는 방법을 다룰 것이다.</p>

<h3 id="432-logistic-regression">4.3.2 Logistic regression</h3>

<p>먼저 two-class classification 문제를 생각해보자. 4.2절에서 continuous input의 경우 
<span>$p(C_1|\mathbf{x}) = \sigma(\mathbf{w}^{T}\mathbf{x}+w_0)$</span>
의 형태로 주어지는 것을 보였고, 
<span>$\mathbf{w},w_0$</span>
는 Gaussian Parameter들의 조합으로 주어졌다. 여기서 착안하여, 임의의 parameter 
<span>$\mathbf{w}$</span>
에 대해</p>

\[p(C_1|\phi) = y(\phi) = \sigma(\mathbf{w}^T\phi)\]

<p>식을 만족하는 모델을 생각할 수 있는데, (여기서 $\phi$는 4.3.1에서의 feature vector $\phi(\mathbf{x})$) 이것이 Logistic Regression Model 이다.</p>

<p>Logistic regression의 장점은 4.2절에서 Gaussian class conditional density를 통해 Generative Model을 만들었던 것에 비해 추정해야할 parameter의 개수가 훨씬 적다는 것이다. Gaussian density를 이용할 경우 D-dimension feature에 대해 $D(D+5)/2 + 1$ 개의 parameter를 추정해야 하지만, Logistic regression의 경우 $\mathbf{w}$ 안의 $D$개의 parameter만 추정하면 된다.</p>

<p>이제 다시 Maximum Likelihood Estimation을 이용해 parameter를 추정하면 되는데, likelihood function은</p>

\[p(\mathbf{t}|\mathbf{w}) = \prod_{n = 1}^{N}y_n^{t_n}(1-y_n)^{1-t_n}\]

<p>의 형태를 가지며 여기서 $y_n = \sigma(\mathbf{w}^T\phi_n)$을 의미한다. Likelihood function에 다시 -log 를 취해서 error function의 형태로 만들어주면</p>

\[E(\mathbf{w}) = -\sum_{n = 1}^{N}\{t_nln\ y_n  + (1-t_n)ln \ (1-y_n) \}\]

<p>의 형태가 되어 그 gradient는</p>

\[\bigtriangledown E(\mathbf{w}) = \sum_{n = 1}^{N}(y_n - t_n)\phi_n\]

<p>의 형태를 갖는다. 이는 error에 basis function vector를 곱한 형태로, 3장에서 linear regression model과 동일한 형태로 주어진 것을 알 수 있다. 또한, 이러한 MLE 추정은 linearly separable 한 데이터에서 극심한 over-fitting 문제를 보이는데, 이런 경우 MAP를 사용하거나 error function에 regularization을 주는 것을 통해 해결할 수 있다.</p>

<h3 id="433-iterative-reweighted-least-squares">4.3.3 Iterative reweighted least squares</h3>

<p>Logistic regression의 경우 sigmoid function의 non-linearity로 인해 MLE의 closed form solution이 존재하지 않기 때문에 Newton-Raphson iterative optimization</p>

\[\mathbf{w}^{new} = \mathbf{w}^{old} - H^{-1}\bigtriangledown E(\mathbf{w})\]

<p>을 통해 문제를 해결하는데, 여기서 H는 $E(\mathbf{w})$의 Hessian matrix이다. (참고로 linear regression 문제에 Newton-Raphson을 사용하면 1 step에 문제가 풀린다.) 이제 해당 방법을 logistic regression에 적용하면,</p>

\[\begin{aligned}
\bigtriangledown E(\mathbf{w}) &amp;= \sum_{n=1}^{N}(y_n-t_n)\phi_n = \Phi^T(\mathbf{y}-\mathbf{t}) \\
H &amp;= \sum_{n=1}^{N}y_n(1-y_n)\phi_n\phi_n^T = \Phi^TR\Phi
\end{aligned}\]

<p>임을 이용해서 (여기서 $R$은 $R_{nn} = y_n(1-y_n)$를 갖는 diagonal matrix이다.)</p>

\[\mathbf{w}^{new} = (\Phi^TR\Phi)^{-1}\Phi^TR\mathbf{z}\]

<p>식을 세울 수 있다. 여기서 $\mathbf{z}$는</p>

\[\mathbf{z} = \Phi\mathbf{w}^{old} - R^{-1}(\mathbf{y} - \mathbf{t})\]

<p>를 의미한다.사실 위 형태는 weighted least square의 형태와 동일하며 실제로 $R$은 $t$의 variance matrix로 해석할 수 있다. 또한, $R$이 constant가 아닌 $\mathbf{w}$를 포함하는 matrix이기 때문에 iterative하게 계산을 해야하는데, 이로 인해 이 알고리즘을 iterative reweighted least square (IRLS)라고 부른다. 참고로, $H$가 positive definite 하다는 특성으로 인해 error function은 $\mathbf{w}$의 concave 함수가 되어 at most one unique solution을 찾을 수 있다.</p>

<h3 id="434-multiclass-logistic-regression">4.3.4 Multiclass logistic regression</h3>

<p>이러한 logistic regression의 개념을 4.2절에서 다뤘던 multiclass로도 확장할 수 있는데</p>

\[p(C_k|\phi) = y_k(\phi) = \cfrac{exp(a_k)}{\sum_jexp(a_j)}\]

<p>where $a_k = \mathbf{w}_k^T\phi$ 로 두고 $\mathbf{w}_k$에 대한 maximum likelihood를 직접적으로 계산하면 된다.</p>

<p>Likelihood function은</p>

\[p(\mathbf{T}|\mathbf{w}_1,...,\mathbf{w}_k) = \prod_{n=1}^{N}\prod_{k=1}^{K}y_{nk}^{t_{nk}}\]

<p>로 주어지며, 여기서 $y_{nk} = y_k(\phi_n)$를 의미한다. 이후 Logistic regression과 동일한 과정을 거쳐 Newton-Raphson method를 사용해 문제를 해결할 수 있다.</p>

<p>참고로, Multiclss에서도 error function에 대한 gradient가</p>

\[\bigtriangledown_{\mathbf{w}_{j}}E(\mathbf{w_1},...,\mathbf{w}_k) = \sum_{n=1}^N(y_{nj} - t_{nj})\phi_n\]

<p>으로 나타나 error에 feature vector를 곱한 형태가 되는데, 사실 이는 general result로 4.3.6절에서 이에 대해 다룰 것이다.</p>

<h3 id="435-probit-regression">4.3.5 Probit regression</h3>

<p>다시 two-class 문제로 돌아와서 sigmoid function이 아닌 다른 activation fuction을 이용하는 더 general한 케이스가 있을 수 있는지 살펴보자. 이를 위해 noisy threshold model을 생각할 수 있는데, $a_n = \mathbf{w}^T\phi_n$ 에 대해</p>

\[\begin{cases}
      t_n = 1 &amp; \text{if}\ a_n \geq \theta \\
      t_n = 0, &amp; \text{otherwise}
\end{cases}\]

<p>인 모델을 생각해보자. 여기서 $\theta$를 probability density $p(\theta)$에서 draw 한다고 생각하면 activation function은</p>

\[f(a) = \int_{-\infty}^{a}p(\theta)d\theta\]

<p>로 주어질 것이며, 특히 density $p(\theta)$를 zero mean unit variance Gaussian이라 가정하면 probit function $\Phi(a)$를 activation function으로 사용할 수 있으며, 이런 경우를 probit regression이라 부른다. 기본적으로 probit regression은 logistic regression과 유사한 결과를 보여주지만 이후 4.5 절에서 Bayesian treatment와 관련하여 probit model을 다룰 것이다.</p>

<p>Probit regression의 특징 중 하나는 logistic regression에 비해 outlier에 더 sensitive 하다는 것이지만 기본적으로 logistic regession과 probit regression 모두 data가 올바르게 label 되었다고 가정한다. 만약, mislabeling에 대한 부분을 생각한다면 mislabel에 대한 확률 $\epsilon$을 probabilistic model에 incorporate 하여</p>

\[p(t|\mathbf{x}) = (1 - \epsilon)\sigma(\mathbf{x}) + \epsilon(1-\sigma(\mathbf{x}))\]

<p>로 두고 문제를 풀 수도 있다.</p>

<h3 id="436-canonical-link-functions">4.3.6 Canonical link functions</h3>

<p>앞서 linear regression, logistic regression 그리고 multiclass logistic regression에서 모두 gradient가 error에 feature vector를 곱한 형태로 나온다는 것을 확인했다. 이번 절에서는 이 result가 특정 조건에서 general result임을 보일 것이다.</p>

<p>먼저 target variable의 conditional distribution이 exponential family 임을 가정하여</p>

\[p(t|\eta,s) = \cfrac{1}{s}h\bigg(\cfrac{t}{s}\bigg)g(\eta)exp\bigg\{\cfrac{\eta t}{s}\bigg\}\]

<p>으로 쓰자. 그러면 $t$의 conditional mean $y$는</p>

\[y \equiv E(t|\eta) = -s\cfrac{d}{d\eta}ln \ g(\eta)\]

<p>로 주어진다. 이러한 $y$와 $\eta$ 사이의 관계를 이용하여 반대로 $\eta = \psi(y)$를 만족하는 $\psi$를 찾을 수 있을 것이다. 또한 log likelihood function을 구하면</p>

\[ln \ p(\mathbf{t}|\eta,s) = \sum_{n = 1}^{N}ln \ p(t_n|\eta,s) = \sum_{n=1}^{N}\bigg\{ ln \ g(\eta_n) + \cfrac{\eta_n t_n}{s}\bigg\} + const\]

<p>로 주어진다.</p>

<p>이제 다시 generalized linear model을 정의하여 $y_n = f(a_n) =f(\mathbf{w}^T\phi_n)$ 로 두자. 여기서 $f$ 는 activation function, $f^{-1}$는 link function으로 정의된다. Log likelihood function을 $\mathbf{w}$에 대해 미분하면</p>

\[\begin{aligned}
\bigtriangledown_{\mathbf{w}}ln \ p(\mathbf{t}|\eta,s) &amp;= \sum_{n = 1}^{N}\bigg\{\cfrac{d}{d\eta_n} \ ln \ g(\eta_n) + \cfrac{t_n}{s}\bigg\}\cfrac{d\eta_n}{dy_n}\cfrac{dy_n}{da_n}\bigtriangledown_{a_n} \\
&amp;= \sum_{n = 1}^{N}\cfrac{1}{s}\{t_n - y_n\}\psi'(y_n)f'(a_n)\phi_n
\end{aligned}\]

<p>으로 gradient를 구할 수 있다. 이때, link function을</p>

\[f^{-1}(y) = \psi(y)\]

<p>로 두면 $f(\psi(y)) = y$로 부터 $f’(\psi)\psi’(y) = 1$ 임을 알 수 있고 (chain rule), $a_n = f^{-1}(y_n)$임을 이용하여 $a = \psi(y_n)$ 로 주어지기 때문에 최종적으로 $f’(a_n)\psi’(y_n) = 1$ 로 주어진다. 따라서 graidient가</p>

\[\bigtriangledown_{\mathbf{w}}E(\mathbf{w}) =\sum_{n = 1}^{N}\cfrac{1}{s}\{t_n - y_n\}\phi_n\]

<p>로 주어져 우리가 아는 error에 feature vector의 곱으로 나타남을 보일 수 있다. 이때 해당 link function을 canonical link fuction이라 부른다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[4.3 Probabilistic Discriminative Model]]></summary></entry><entry><title type="html">PRML 스터디 Chap.4.2</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-2/" rel="alternate" type="text/html" title="PRML 스터디 Chap.4.2" /><published>2022-01-20T00:00:00+09:00</published><updated>2022-01-20T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-2</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-4-2/"><![CDATA[<h3 id="416-fishers-discriminant-for-multiple-classes">4.1.6 Fisher’s discriminant for multiple classes</h3>

<p>이제는 기존의 Binary Classification을 넘어, Fisher’s LDA를 이용해 multiple class discrimination을 어떻게 수행하는지 다룰 것이다. K(&gt;2) 개의 class가 있고, input space의 dimension이 D라고 가정하자 (D &gt; K). 이전의 Binary Classification에서는 1차원으로 데이터를 Project 했지만, 이번에는 더 확장하여 임의의 D’ 차원으로 Project하는 방법을 다룰 것이다. 이를 위해 weight vector $\mathbf{w}_d$ (d = 1,…,D’)를 정의하여 D’개의 `linear feature’ $y_d = \mathbf{w}_d^T\mathbf{x}$ 를 생성할 수 있다. 이를 Vector와 Matrix from으로 한번에 나타내면</p>

\[\mathbf{y} = \mathbf{W}^T\mathbf{x}\]

<p>로 둘 수 있을 것이다.</p>

<p>이제 Binary Classification 때와 동일하게 within-class covariance matrix와 between-class covariance matrix를 정의해야 하는데, within-class covaraince matrix는 이전과 동일한 방식으로</p>

\[\mathbf{S}_W = \sum_{k=1}^{K}\mathbf{S}_k\]

<p>로 정의할 수 있다. (여기서 $\mathbf{S}_k$는 각 class 내에서의 covariance matrix)</p>

<p>Multiple class 간의 between-class covariance matrix의 경우 total covariance matrix</p>

\[\mathbf{S}_T = \sum_{n=1}^N(\mathbf{x}_n - \mathbf{m})(\mathbf{x}_n - \mathbf{m})^T\]

<p>와 covariance matrix 간의 관계</p>

\[\mathbf{S}_T = \mathbf{S}_W + \mathbf{S}_B\]

<p>를 이용하여</p>

\[\mathbf{S_B} = \sum_{k=1}^K N_k(\mathbf{m}_k - \mathbf{m})(\mathbf{m}_k - \mathbf{m})^T\]

<p>가 됨을 알 수 있다.</p>

<p>Linear Features $\mathbf{y}$의 공간에서도 동일한 방법으로 Multiple class 간의 $s_W$ 와 $s_B$를 구할 수 있다. 이후 역시 between-class covariance는 크게하면서 within-class covariance를 작게하기 위해</p>

\[J(W) = Tr\{s_W^{-1}s_B\} = Tr\{(\mathbf{W}\mathbf{S}_W\mathbf{W}^T)^{-1}(\mathbf{W}\mathbf{S}_B\mathbf{W}^T)\}\]

<p>를 최대화하는 $\mathbf{W}$를 찾으면 된다. 이때, optimal $\mathbf{W}$는 $\mathbf{S}_W^{-1}\mathbf{S}_B$의 D’개의 Largest Eigenvalue에 대응하는 Eigenvector들로 구할 수 있음이 알려져있다. 또한, $\mathbf{S}_B$의 formulation 상 rank가 최대 (K-1) 이기 때문에, 의미가 있는 D’는 최대 (K-1)까지만 가능하다는 것을 알 수 있다. 즉, Binary classification에서는 1차원으로의 projection이 최선인 것이다.</p>

<h3 id="417-the-perceptron-algorithm">4.1.7 The Perceptron algorithm</h3>

<p>또 다른 linear discriminant 모델로 Perceptron algorithm을 들 수 있다. 먼저 input vector $\mathbf{x}$를 fixed nonlinear transfromation을 통해 feature vector $\phi(\mathbf{x})$로 mapping한 뒤 (bias term 포함),</p>

\[y(\mathbf{x}) = f(\mathbf{w}^T\phi(\mathbf{x}))\]

<p>식을 통해 $y(\mathbf{x})$를 계산해주는데, 이때 $f(x)$는 step function으로</p>

\[f(x) = \begin{cases}
  +1, &amp; x \geq 0 \\
  -1, &amp; x &lt; 0
\end{cases}\]

<p>의 형태를 가진다. Step function의 값에 맞춰 Perceptron algorithm에서는 target value를 $C_1$의 경우 $t = +1$, $C_2$의 경우 $t = -1$ 로 둔다. 이제, target value를 잘 맞추는 $\mathbf{w}$를 구해주기만 하면 되는데 이를 구하는 analytic한 방법은 없고 gradient descent 방법을 사용한다. Gradient desecent를 이용하기 위해서는 error function을 정의해야 하는데, Perceptron algorithm의 형태를 보면, class를 잘 맞춘 경우에는 $\mathbf{w}^T\phi(\mathbf{x}_n)t_n$ 값이 양수를 class를 잘 맞추지 못한 경우는 음수를 가진다는 것을 알 수 있다. 이를 이용해 perceptron criterion이라 불리는 error function</p>

\[E_p(\mathbf{w}) = - \sum_{n \in M}\mathbf{w}^T\phi(\mathbf{x_n})t_n\]

<p>을 정의하여 (여기서 $M$은 Class를 맞추지 못한 observation들을 의미한다) gradient descent 방법을 통해 $\mathbf{w}$를 update 한다. 즉,</p>

\[\mathbf{w}^{(t+1)} = \mathbf{w}^{(t)} - \eta\bigtriangledown E_p(\mathbf{w}) = \mathbf{w}^{(t)} +\eta\phi(\mathbf{x_n})t_n\]

<p>의 계산을 통해 $\mathbf{w}$를 구할 수 있다. 해당 방법은 perceptron convergence theorem에 따라서 data가 linearly separable 하다면 finite steps 안에 converge 한다는 것이 증명되어 있다. 하지만, linearly separable 하지 않은 경우 perceptron algorithm은 solution을 찾을 수 없으며, 이를 해결하기 위해서 perceptron algorithm 여러개를 이어 붙이는 형태의 알고리즘이 등장하게 된다. 이로인해 perceptron algorithm을 Neural Network의 조상으로 보는 시각도 존재한다.</p>

<h2 id="42-probabilistic-generative-model">4.2 Probabilistic Generative Model</h2>

<p>지금까지 다뤘던 Classification 모델들은 Discriminative approach로 observation이 어느 class에 속하는지만 알려준다는 한계가 있다. 이에 반해 Probabilistic Generative approach는 어느 class에 속할 확률을 모델링하는 방법으로 굉장히 유용한 접근방법이다. 이를 위해 class conditional density 
<span>$p(\mathbf{x|C_k})$</span>
와 class priors 
<span>$p(C_k)$</span>
를 먼저 구하고, Bayes’ Theorem을 이용해 posterior 
<span>$p(C_k|\mathbf{x})$</span>
를 구하는 방식이 일반적이다.</p>

<p>먼저, two class classification 문제를 생각해보자. $C_1$에 대한 posterior probability는</p>

\[\begin{aligned}
p(C_1|\mathbf{x}) &amp;= \cfrac{p(\mathbf{x}|C_1)p(C_1)}{p(\mathbf{x}|C_1)p(C_1) + p(\mathbf{x}|C_2)p(C_2)} \\ &amp;= \cfrac{1}{1 + exp(-a)} = \sigma(a) 
\end{aligned}\]

<p>where</p>

\[a = ln\cfrac{p(\mathbf{x}|C_1)p(C_1)}{p(\mathbf{x}|C_2)p(C_2)}\]

<p>으로 구할 수 있다. 여기서 $\sigma$는 sigmoid function</p>

\[\sigma(a) = \cfrac{1}{1 + exp(-a)}\]

<p>을 의미한다.</p>

<p>이를 multiple class로 확장하면,</p>

\[p(C_k|\mathbf{x}) = \cfrac{p(\mathbf{x}|C_k)p(C_k)}{\sum_jp(\mathbf{x}|C_j)p(C_j)} = \cfrac{exp(a_k)}{\sum_jexp(a_j)}\]

<p>where</p>

\[a_k = ln \ p(\mathbf{x}|C_k)p(C_k)\]

<p>로 구할 수 있으며 이는 softmax function의 형태와 동일하다.</p>

<h3 id="421-continuous-inputs">4.2.1 Continuous inputs</h3>

<p>먼저 input vector $\mathbf{x}$가 continuous 인 경우, 특히 class-conditional density가 Gaussian인 경우를 살펴보자.</p>

\[p(\mathbf{x}|C_k) = \cfrac{1}{(2\pi)^{D/2}}\cfrac{1}{|\Sigma|^{1/2}}exp \bigg\{-\cfrac{1}{2}(\mathbf{x}-\mathbf{u}_k)^T\Sigma^{-1}(\mathbf{x}-\mathbf{u}_k)\bigg\}\]

<p>라고 할 때 (Class가 같은 covariance matrix를 공유한다고 가정), 위 식에 대입을 통해</p>

\[p(C_1|\mathbf{x}) = \sigma(\mathbf{w}^T\mathbf{x} + w_0)\]

<p>where</p>

\[\mathbf{w} = \Sigma^{-1}(\mathbf{u}_1 - \mathbf{u}_2)\]

\[w_0 = -\cfrac{1}{2}\mathbf{u}_1^{T}\Sigma^{-1}\mathbf{u_1} + \cfrac{1}{2}\mathbf{u}_2^{T}\Sigma^{-1}\mathbf{u_2} + ln\cfrac{p(C_1)}{p(C_2)}\]

<p>로 정리 됨을 알 수 있다. 즉, posterior 분포가 $\mathbf{x}$에 대해서 linear 한 형태 (sigmoid 함수 안에서)가 된다. 그리고 prior $p(C_k)$는 parallel shift에만 영향을 미침을 알 수 있다.</p>

<p>K개의 class가 있는 경우로 확장하여도 다시 대입을 통해</p>

\[a_k(\mathbf{x}) = \mathbf{w}_k\mathbf{x} + w_{k0}\]

<p>where</p>

\[\mathbf{w}_k = \Sigma^{-1}\mathbf{u}_k\]

\[w_{k0} = -\cfrac{1}{2}\mathbf{u}_k^{T}\Sigma^{-1}\mathbf{u_k} + ln \ p(C_k)\]

<p>임을 알 수 있다. 역시 $\mathbf{x}$에 대해서 linear한 form으로 나타남을 확인 할 수 있는데, 이는 각 class가 동일한 covariance matrix를 공유한다는 가정으로 인한 것으로 모두 다른 covariance matrix를 가정하면 quadratic한 형태를 가지게 되어 quadratic discriminant boundary를 가지게 된다.</p>

<h3 id="422-maximum-likelihood-solution">4.2.2 Maximum likelihood solution</h3>

<p>이제, parametric form을 모두 구했으므로 MLE를 통해 parameter 값을 estimate 해야한다. Prior $p(C_1) = \pi$ 라 하고 $C_1$에 속하는 경우를 $t_n$ =1 로 두자. 그럼 반대로 $p(C_2) = (1 - \pi)$가 될 것이며 $C_2$에 속하는 경우 $t_n$ = 0으로 두자. 그럼</p>

\[p(\mathbf{x}_n,C_1) = p(C_1)p(\mathbf{x_n}|C_1) = \pi N(\mathbf{x_n|\mathbf{u}_1,\Sigma})\]

\[p(\mathbf{x}_n,C_2) = p(C_2)p(\mathbf{x_n}|C_2) = \pi N(\mathbf{x_n|\mathbf{u}_2,\Sigma})\]

<p>가 되어 최종 likelihood function은</p>

\[p(\mathbf{t}|\pi,\mathbf{u}_1,\mathbf{u}_2,\Sigma) = \prod_{n = 1}^{N}[\pi N(\mathbf{x_n|\mathbf{u}_1,\Sigma})]^{t_n}[\pi N(\mathbf{x_n|\mathbf{u}_2,\Sigma})]^{1-t_n}\]

<p>으로 나타난다. 해당식에 log를 취한 뒤 각 parameter로 미분하여 최적값을 찾으면,</p>

\[\hat{\pi} = \cfrac{N_1}{N_1 + N_2}\]

\[\hat{\mathbf{u}}_1 = \cfrac{1}{N_1}\sum_{n = 1}^{N}t_n\mathbf{x_n}\]

\[\hat{\mathbf{u}}_2 = \cfrac{1}{N_2}\sum_{n = 1}^{N}(1 - t_n)\mathbf{x_n}\]

\[\hat{\Sigma} = \cfrac{N_1}{N}S_1 + \cfrac{N_2}{N}S_2\]

<p>where</p>

\[S_1 = \cfrac{1}{N_1}\sum_{n \in C_1}(\mathbf{x}_n - \mathbf{u}_1)(\mathbf{x}_n - \mathbf{u}_1)^{T}\]

\[S_2 = \cfrac{1}{N_2}\sum_{n \in C_2}(\mathbf{x}_n - \mathbf{u}_2)(\mathbf{x}_n - \mathbf{u}_2)^{T}\]

<p>로 원하는 값들을 찾을 수 있다. Multiple class의 경우에도 동일한 방법을 통해 각 parameter를 어렵지 않게 찾을 수 있다.</p>

<h3 id="423-discrete-features">4.2.3 Discrete features</h3>

<p>이제 Continuous 한 경우가 아닌 input이 discrete 한 경우를 생각해보자. 간단하게 binary case를 생각해보면, D dimension input vector는 각 $x_i \in {0,1}, i = 1,…,D$ 로 이루어질 것이고 전체 distribution은 각 class 별로 $2^D$개의 숫자로 이루어진 table로 표현될 것이다. (Summation constraint 때문에 실제 independent한 변수는 $(2^D - 1)$개)</p>

<p>여기서 각 feature value가 $C_k$에 대해 conditionally independent 하다는 naive Bayes 가정을 하면, class-conditional distribution은</p>

\[p(\mathbf{x}|C_k) = \prod_{i = 1}^{D}u_{ki}^{x_i}(1 - u_{ki})^{1-x_i}\]

<p>의 형태를 가진다. 이후, 이를 위의 $a_k$를 구하는 식에 대입하면,</p>

\[a_k(\mathbf{x}) = \sum_{i = 1}^{D}\{x_iln \ u_{ki} + (1-x_i) ln \ (1-u_{ki})\} + ln \ p(C_k)\]

<p>로 나타남을 알 수 있다. Binary case가 아닌 Multicategory case에도 같은 방식으로 식을 유도할 수 있다.</p>

<h3 id="424-exponential-family">4.2.4 Exponential Family</h3>

<p>사실 Continuous (Normal) 혹은 Discrete (Bernoulli)한 경우 외에도 Exponential Family에서 속하는 모든 확률 분포를 class-conditional distribution으로 사용할 수 있기 때문에 다양한 형태의 input vector에 대해서 Generative Model을 만들어낼 수 있다.</p>

<p>일반적인 Exponential Family의 p.d.f.는</p>

\[p(\mathbf{x}|\boldsymbol{\lambda}_k) = h(\mathbf{x})g(\boldsymbol{\lambda}_k)exp\{\boldsymbol{\lambda}_k^{T}\mathbf{u}(\mathbf{x})\}\]

<p>로 나타나는데 (Class 별로 $\boldsymbol{\lambda}_k$가 다른 값을 가진다고 가정), 이 중 $u(\mathbf{x}) = \mathbf{x}$ 인 경우만 생각하고 scaling parameter $s$를 도입하면,</p>

\[p(\mathbf{x}|\boldsymbol{\lambda}_k, s) = \cfrac{1}{s}h\bigg(\cfrac{1}{s}\mathbf{x}\bigg)g(\boldsymbol{\lambda}_k)exp\bigg\{\cfrac{1}{s}\boldsymbol{\lambda}_k^{T}\mathbf{x}\bigg\}\]

<p>으로 나타낼 수 있다. 해당 class-conditional distribution을 이용하면 binary classification의 경우에는</p>

\[a(\mathbf{x}) = (\boldsymbol{\lambda}_1 - \boldsymbol{\lambda}_2)^{T}\mathbf{x} + ln \ g(\boldsymbol{\lambda}_1) - ln \ g(\boldsymbol{\lambda}_2) + ln \ p(C_2) - ln \ p(C_1)\]

<p>으로 나타나며 multiple class의 경우</p>

\[a_k(\mathbf{x}) = \boldsymbol{\lambda}_k^T\mathbf{x} + ln \ g(\boldsymbol{\lambda}_k) + ln \ p(C_k)\]

<p>로 나타나는데, 모두 $\mathbf{x}$ 에 대해서 linear 한 형태를 가지고 있음을 알 수 있다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[4.1.6 Fisher’s discriminant for multiple classes]]></summary></entry><entry><title type="html">PRML 스터디 Chap.3.4</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-4/" rel="alternate" type="text/html" title="PRML 스터디 Chap.3.4" /><published>2021-11-19T00:00:00+09:00</published><updated>2021-11-19T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-4</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-4/"><![CDATA[<p>(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)</p>

<p>PRML 3.4절의 주제는 Bayesian Model Comparison이다. 3.4절에서는 굉장히 conceptual 한 내용이 나와서 한번에 이해하기 쉽지 않을 수 있지만, 3.5절에서 더 구체적 예시를 통해 설명하니 쉽게 이해가 되지 않아도 너무 걱정하지 말자.</p>

<h2 id="34-bayesian-model-comparison">3.4 Bayesian Model Comparison</h2>

<p>이번 절에서는 베이지안 관점에서 모델 (혹은 하이퍼파라미터)를 선택하는 방법에 대해 다룬다. 기본적으로, 모델 선택에는 Cross Validation과 같은 방법이 많이 사용되지만, 해당 방법은 Validation Set을 따로 남겨둬야해서 전체 데이터를 Training 과정에 사용할 수 없다는 단점이 있다. 반면에 Bayesian Model Comparison은 Train Set 만으로도 Model Comparison을 가능하게 해준다.</p>

<p>먼저, 비교할 모델의 Set이 ${M_i}$ where $i = 1,…,L$ 로 존재한다고 하자. 여기서 각 모델은 관측된 데이터에 대한 확률분포로 해석할 수 있고, 데이터가 이 중 하나의 모델에서 생성되었지만 어떤 모델에서 나온 것인지 알 수 없는 상황이라 볼 수 있다. 이런 불확실성은 prior probability distribution $p(M_{i})$로 나타낼 수 있고 (각 모델에 대한 기본적 선호도를 나타낸다고 볼 수 있다), 주어진 데이터를 통해 posterior를 구해야할 것이다. 이때 posterior distribution은</p>

\[p(M_{i}|D) \propto p(M_{i})p(D|M_{i})\]

<p>으로 주어진다. 이때, 단순하게 prior는 모두 동일한 케이스를 가정하자.</p>

<p>그럼, 주목해야할 항은 <em>model evidence</em> 혹은 <em>marginal likelihood</em>로 불리는 
<span>$p(D|M_{i})$</span>
이다. 이는 주어진 모델에 대해서 각 데이터의 확률분포를 나타낸다고 생각할 수 있다.2개 모델의 model evidence 간의 비율 
<span>$p(D|M_{i})/p(D|M_{j})$</span>
는 <em>Bayes Factor</em>라 불린다.</p>

<p>이제 posterior distribution을 이용해서 predictive distribution</p>

\[p(t|\mathbf{x},D) = \sum_{i = 1}^{L}p(t|\mathbf{x},M_{i},D)p(M_{i}|D)\]

<p>을 구할 수 있다. 이는 <em>mixture distribution</em>의 일종으로, 각 모델의 posterior를 weight로 사용하여 predictive distribution을 평균낸 것으로 이해할 수 있다. 하지만 가장 쉬운 방법은 가장 가능성이 높은 모델 하나만 사용하는 것이기에 주로 <em>Model Selection</em>을 진행한다.</p>

<p>다시 Model Evidence에 대한 이야기로 돌아와 모델이 parameter $\mathbf{w}$에 의해 결정되는 케이스를 생각해보자. 그렇다면 model evidence는</p>

\[p(D|M_{i}) = \int p(D|\mathbf{w},M_{i})p(\mathbf{w}|M_{i})d\mathbf{w}\]

<p>로 주어진다. Sampling 관점에서는 model evidence는 prior에 의해 random으로 생성된 parameter로 정의된 모델에서 해당 data set $D$를 generaete할 확률로 이해할 수 있다. 또한, parameter에 대한 posterior를 계산할 때,</p>

\[p(\mathbf{w}|D,M_{i}) = \cfrac{p(D|\mathbf{w},M_{i})p(\mathbf{w}|M_i)}{p(D|M_i)}\]

<p>으로 계산되기에 model evidence가 normalizing term으로 쓰인다는 것도 흥미로운 지점으로 생각할 수 있다.</p>

<p>Parameter $w$에 (dimension이 1인 단순한 경우를 가정) 대한 적분을 통해 model evidence에 대한 더 흥미로운 insight를 얻을 수 있다. Parameter의 posterior distribution은 
<span>$p(D|w)p(w)$</span> 
에 비례하는데 (Model notation 생략), posterior 분포가 
<span>$w_{MAP}$</span>에 굉장히 몰려있고, 그 width를 
<span>$\triangle w_{posterior}$</span>이라 가정하자. 또한, prior가 flat한 형태에 width가 
<span>$\triangle w_{prior}$</span>이라 가정하면 (
<span>$p(w) = 1/\triangle w_{prior}$</span>
),</p>

\[p(D) = \int p(D|w)p(w)dw \approx p(D|w_{MAP})\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\]

<p>으로 둘 수 있고, 양변에 $log$를 취하면,</p>

\[ln\ p(D) \approx p(D|w_{MAP}) + ln\bigg(\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\bigg)\]

<p>으로 주어진다.</p>

<p><img src="/assets/img/2021-11-19-prml-스터디-chap-3-4/Figure%203.12.png" alt="" /></p>

<p>첫번째 항은 가장 가능성이 높은 parameter value에 기반한 data fit을 의미하며, prior가 flat 하다면 이는 log likelihood와 동일하다. 두번째 항은 Model Complexity에 따른 penalty 항으로 이해할 수 있다. $\triangle w_{posterior} &lt; \triangle w_{prior}$ 이면 두번째 항은 negative value를 가지고, $\triangle w_{posterior} / \triangle w_{prior}$ 비율이 작아질 수록 magnitude가 커지게 된다. 즉, parameter가 posterior distribution의 데이터에 더 fitted 되어있을 수록 penalty term이 커지게 된다.</p>

<p>이제 모델이 $M$개의 parameter를 가지고 있고, 모든 parameter가 동일한 $\triangle w_{posterior} / \triangle w_{prior}$ 비율을 가지고 있다고 가정하자. 그렇다면,</p>

\[ln\ p(D) \approx p(D|\mathbf{w}_{MAP}) + M\ ln\bigg(\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\bigg)\]

<p>으로 나타낼 수 있다. Model complexity가 높아질 수록 첫번째 항은 줄어들겠지만, 두번째 항은 M에 의존하기 때문에 더욱 커질 것이며 maximum evidence로 결정되는 optimal model complexity는 이 2개 항의 trade-off 사이에서 주어지게 된다.</p>

<p>이제, marginal likleihood (model evidence)를 통해 어떻게 intermediate complexity 모델이 선택될 수 있는지 살펴보자. 아래의 그림에서 x 축은 가능한 데이터셋의 one-dimensional representation이며 특정 point는 특정한 데이터셋을 의미한다고 생각할 수 있다.</p>

<p><img src="/assets/img/2021-11-19-prml-스터디-chap-3-4/Figure%203.13-01.png" alt="" /></p>

<p>이제 각 Model Complexity에 따른 $p(D)$의 형태를 생각해보자. 가장 간단한 모델인 $M_1$에서 데이터가 랜덤하게 생성된다고 생각하면, 생성된 데이터셋들의 분산은 상대적으로 작을 것이며 서로 비슷한 모양을 가질 것이다. 반대로, 모델이 복잡해질 수록 생성될 수 있는 형태의 데이터셋이 다양해질 것이고, $M_3$처럼 더 Sparse 한 Distribution을 가지게 될 것이다. 이 때, 
<span>$p(D|M_i)$</span>
는 Normalize 되어야하기 때문에, 그림에서 처럼 특정 데이터셋 포인트에서는 intermediate complexity model의 model evidence가 가장 커질 수 있는 것이다.</p>

<p>Bayesian Model Comparison의 기본적인 가정은 실제로 데이터가 현재 고려 중인 모델 중 하나에서 생성되었다는 것이다. 해당 가정이 사실이라고 했을 때, Bayesian Model Comparison은 평균적으로 correct model을 선택할 수 있게 해준다. 2개의 Model $M_1,M_2$ 가 있다고 하고, correct model이 $M_1$인 경우를 생각하자. Bayes factor를 데이터셋의 실제 분포 (correct model)로 평균을 내면</p>

\[\int p(D|M_1)ln\cfrac{p(D|M_1)}{p(D|M_2)}dD\]

<p>로 나타날 것이다. 이는 <em>Kullback-Leibler</em> <em>divergence</em> 의 형태로 항상 양수 값을 가지며 2개의 distribution이 동일한 경우에만 0의 값을 가진다. 즉, 평균적으로 Bayes factor는 항상 correct model을 찾아내는 것이다.</p>

<p>Bayesian Model Comparison은 over-fitting 문제를 피하고 train data 만으로 비교를 가능하게 해주지만, 여전히 다른 머신러닝 문제처럼 여러 가정이 필요하고 해당 가정이 사실이 아니라면 그 결과를 믿을 수 없게 된다. 이에, 실제 문제에있어서는 test set 데이터를 따로 두고 최종 system의 performance를 체크하는 것이 현명할 것이다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)]]></summary></entry><entry><title type="html">PRML 스터디 Chap.3.3</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-3/" rel="alternate" type="text/html" title="PRML 스터디 Chap.3.3" /><published>2021-11-14T00:00:00+09:00</published><updated>2021-11-14T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-3</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-3-3/"><![CDATA[<p>(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)</p>

<p>PRML 3.3절의 주제는 Bayesian Linear Regression이다. 이전 3.1, 3.2절에서 다뤘던 Linear Regression을 베이지안의 관점에서 모델링한 결과를 보여준다. Bayesian Linear Regression은 특히 더 뒤에 Chapter에서 다룰 Gaussian Process와 깊은 관련이 있으니 열심히 공부하도록 하자.</p>

<h2 id="33-bayesian-linear-model">3.3 Bayesian Linear Model</h2>

<p>기존의 Linear Regression 은 Maximum Likelihood Estimation에 의존하기 때문에, Model Complexity를 제어하기 힘들며, overfitting이 쉽게 일어날 수 있다. 이를 해결하기 위한 Regularization 방법도 이전에 다루었지만, 3.3절에서는 이를 Bayesian Perspective를 통해 해결한다.</p>

<h3 id="331-parameter-distribution">3.3.1 Parameter distribution</h3>

<p>Bayesian Linear Model의 가장 큰 특징은 model parameter인 $\mathbf{w}$를 random variable로 보고 분포를 가정한다는 것이다. 먼저, precision parameter $\beta$가 알려져있다고 하자. Likelihood Function 
$p(t|\mathbf{w}) = N(t|y(\mathbf{x},\mathbf{w}),\beta^{-1})$
이 $\mathbf{w}$에 대해 제곱의 지수꼴을 하고 있기 때문에, $\mathbf{w}$의 conjugate prior는 정규분포가 적합할 것이다.</p>

\[p(\mathbf{w}) = N(\mathbf{w}|\mathbf{m}_0,\mathbf{S}_0)\]

<p>이를 바탕으로 posterior 분포를 계산해보면 (Chap.2 에서의 공식을 이용하여)</p>

\[p(\mathbf{w}|\mathbf{t}) = N(\mathbf{w}|\mathbf{m}_N,\mathbf{S}_N)\]

<p>where</p>

\[\begin {aligned}
\mathbf{m}_N &amp;= \mathbf{S}_N(\mathbf{S}_{0}^{-1}\mathbf{m}_0 + \beta\mathbf{\Phi}^{T}\mathbf{t}) \\ \mathbf{S}_{N}^{-1} &amp;= \mathbf{S}_{0}^{-1} + \beta\mathbf{\Phi}^{T}\mathbf{\Phi}
\end {aligned}\]

<p>임을 알 수 있다.</p>

<p>해당 식을 통해 
<span>$\mathbf{w}_{MAP} = \mathbf{m}_N$</span>
가 되며, 만약 
<span>$\mathbf{S}_0 = \alpha^{-1}\mathbf{I}$</span> 로 두고 
<span>$\alpha \rightarrow 0$</span>
이면 
<span>$\mathbf{m}_N$</span>
은 
<span>$\mathbf{w}_{ML}$</span>
과 같은 값을 가지게 된다. 또한, 
<span>$N = 0$</span>
이면 posterior 분포는 prior와 같은 분포가 된다. 이는 앞서서 보았던 posterior 분포의 일반적 특성과 일치한다.</p>

<p>이제 prior 분포가</p>

\[p(\mathbf{w}|\alpha) = N(\mathbf{w}|0,\alpha^{-1}\mathbf{I})\]

<p>인 단순한 케이스를 생각해보자. 그러면 posterior 분포는</p>

\[\begin {aligned}
\mathbf{m}_N &amp;= \beta\mathbf{S}_N\mathbf{\Phi}^{T}\mathbf{t} \\ \mathbf{S}_{N}^{-1} &amp;= \alpha\mathbf{I} + \beta\mathbf{\Phi}^{T}\mathbf{\Phi}
\end {aligned}\]

<p>의 평균과 분산을 가진다. 그리고 log posterior를 $\mathbf{w}$에 대해서 정리하면,</p>

\[ln\,p(\mathbf{w}|\mathbf{t}) = -\cfrac{\beta}{2}\sum_{n = 1}^{N}\{t_n-\mathbf{w}^{T}\phi(\mathbf{x}_n)\}^{2}-\cfrac{\alpha}{2}\mathbf{w}^{T}\mathbf{w} + const\]

<p>으로 주어진다. 그러므로 posterior를 최대화하는 것은 sum-of-squares error를 최소화하면서 동시에 regularization term이 존재하는 것과 동일하다는 것을 알 수 있다.</p>

<p>Bayesian Approach의 큰 장점 중 하나는 이전에도 다루었듯이 Sequential update가 가능하다는 것이다. 아래의 그림은 $y(x,\mathbf{w}) = w_0 + w_1x$ 이라는 간단한 식을 두고 $w_0,w_1$ 을 반복적으로 update 하는 모습을 보여준다.</p>

<p><img src="/assets/img/2021-11-14-prml-스터디-chap-3-3/Figure%203.7.png" alt="" /></p>

<p>해당 그림을 통해, posterior 분포가 원래의 실제 값인 하얀 십자가에 점점 가까워지는 것을 관측할 수 있고, 선형 식도 데이터에 더 적합하도록 변화하는 것을 볼 수 있다.</p>

<h3 id="332-predictive-distribution">3.3.2 Predictive distribution</h3>

<p>실제 linear regression 문제에서 우리가 관심을 가지는 부분은 $\mathbf{w}$보다는 새로운 데이터가 들어왔을 때 $t$를 정확히 예측하는 것이다. 이를 위해 predictive distribution을 계산하면,</p>

\[p(t|\mathbf{t},\alpha,\beta) = \int{p(t|\mathbf{w},\beta)p(\mathbf{w}|\mathbf{t},\alpha,\beta)d\mathbf{w}}\]

<p>가 되어 ($t$는 예측하고자 하는 target, $\mathbf{t}$는 fitting을 위한 데이터로 주어진 값)</p>

\[p(t|\mathbf{x},\mathbf{t},\alpha,\beta) = N(t|\mathbf{m}_N^T\phi(\mathbf{x}),\cfrac{1}{\beta} +\phi(\mathbf{x})^{T}\mathbf{S}_N\phi(\mathbf{x}))\]

<p>로 주어진다. ($\mathbf{x}$는 예측을 위해 새로 주어진 value) 여기서, 뒤의 분산항을 살펴보면 데이터가 더 많이 관측될 수록 분산이 줄어듦을 알 수 있으며, $N$이 무한대로 가면 순수 noise인 $\beta^{-1}$ 만 남는다는 것을 알 수 있다. 아래의 그림은 Sequential update를 통해 predictive distribution이 어떻게 변화하는지 보여준다. (초록 선이 true model)</p>

<p><img src="/assets/img/2021-11-14-prml-스터디-chap-3-3/Figure%203.8.png" alt="" /></p>

<p>이때, Gaussian과 같은 localized basis function을 사용하면 basis function의 중심에서 벗어난 region에서는 분산항의 2번째 term이 0으로 수렴해서 $\beta^{-1}$ 만 남는 상황이 발생한다. 즉, extraploation에 대해서 굉장히 낮은 variance를 가지게 되는 것인데 이러한 문제는 향후에 소개될 Gaussian Process를 통해 해결할 수 있다.</p>

<p>또한, 지금까지는 $\beta$가 알려져있다고 가정했으나, $\mathbf{w},\beta$가 모두 알려져있지 않다고 가정하면 Chapter 2에서 소개한 Gaussian-Gamma 분포를 prior 분포로 사용할 수 잇다. 이 경우, predictive 분포는 Student’s t 분포로 나타난다.</p>

<h3 id="333-equivalent-kernel">3.3.3 Equivalent kernel</h3>

<p>위에서 주어진 predictive mean을 다시 쓰면</p>

\[y(\mathbf{x},\mathbf{m}_N) = \mathbf{m}_{N}^{T}\phi(\mathbf{x}) = \beta\phi(\mathbf{x})^{T}\mathbf{S}_{N}\Phi^{T}\mathbf{t} = \sum_{n=1}^{N}\beta\phi(\mathbf{x})^{T}\mathbf{S}_{N}\phi(\mathbf{x}_n)t_{n}\]

<p>으로 주어진다. 즉, predictive mean이 training set의 target values인 $t_n$의 linear combination으로 주어짐을 알 수 있고,</p>

\[y(\mathbf{x},\mathbf{m}_N) = \sum_{n=1}^{N}k(\mathbf{x},\mathbf{x}_n)t_n\]

<p>where</p>

\[k(\mathbf{x},\mathbf{x}') = \beta\phi(\mathbf{x})^{T}\mathbf{S}_N\phi(\mathbf{x}')\]

<p>으로 쓸 수 있다. 여기서 $k(\mathbf{x},\mathbf{x}’)$ 함수는 <em>smoother matrix</em> 혹은 <em>equivalent kernel</em> 이라 불린다. 또한, 이렇게 training set의 target values의 linear combination으로 prediction을 하는 회귀식을 <em>linear smoothers</em> 라 부른다.</p>

<p>이때, Gaussian basis function의 equivalent kernel을 살펴보면</p>

<p><img src="/assets/img/2021-11-14-prml-스터디-chap-3-3/3.10.png" alt="" /></p>

<p>의 형태를 가진다는 것을 알 수 있다. 즉, $k(x,x’)$ 에서 서로 비슷한 값을 가질 때 더 큰 값을 가진다는 것인데, 이를 위의 linear lombination과 같이 생각하면 $\mathbf{t}$를 예측하고자 하는 $\mathbf{x}$와 가까운 $\mathbf{x}_n$의 $\mathbf{t}_n$에 더 많은 weight를 부여하는 합리적인 형태라는 것을 알 수 있다. equivalent kernel의 이러한 형태는 다른 Basis function을 사용해도 유지된다. 또한, predictive mean간의 공분산을 계산해보면</p>

\[\begin {aligned}
cov[y(\mathbf{x}),y(\mathbf{x'})] &amp;= cov[\phi(\mathbf{x})^{T}\mathbf{w},\mathbf{w}^{T}\phi(\mathbf{x'})] \\ &amp;= \phi(\mathbf{x})^{T}\mathbf{S}_{N}\phi(\mathbf{x}') = \beta^{-1}k(\mathbf{x},\mathbf{x}')
\end {aligned}\]

<p>으로 주어져, 가까운 지점간의 predictive mean은 상대적으로 큰 Correlation을 가지게 된다.</p>

<p>이렇듯, equivalent kernel을 이용하여 Bayesian Linear Regression의 결과를 나타낼 수 있다는 것에 착안해 Basis Function을 먼저 지정하지 않고, kernel function 만을 가지고 주어진 데이터를 학습하고 새로운 데이터에 대한 예측을 하는 것을 생각해볼 수 있는데, 이는 향후 다룰 Gaussian Process의 Framework가 된다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)]]></summary></entry><entry><title type="html">PRML 스터디 Chap.2 (2)</title><link href="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-2-2/" rel="alternate" type="text/html" title="PRML 스터디 Chap.2 (2)" /><published>2021-09-21T00:00:00+09:00</published><updated>2021-09-21T00:00:00+09:00</updated><id>http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-2-2</id><content type="html" xml:base="http://localhost:4000/prml%20%EC%8A%A4%ED%84%B0%EB%94%94/prml-%EC%8A%A4%ED%84%B0%EB%94%94-chap-2-2/"><![CDATA[<p>(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)</p>

<p>이번에는 PRML 2.3절에 해당하는 Gaussian Distribution에 대한 내용이다. 정규분포 혹은 가우시안 분포로 불리는 Gaussian Distribution은 통계학 그리고 머신러닝에서 정말 중요한 위치를 가지는 분포인 만큼 책에도 많은 내용이 담겨져 있다. 특히, 책에는 수식을 통해 결과값을 유도하는 과정이 많이 담겨져 있는데, 원활한 진행을 위해 해당 부분은 생략하였으니 자세한 증명은 PRML 책 혹은 편한 수리통계학 책을 참고하자.</p>

<h2 id="23-gaussian-distribution">2.3 Gaussian Distribution</h2>

<p>Gaussian Distribution은</p>

\[N(x|u,\sigma^2) = \cfrac{1}{(2\pi\sigma^2)^{1/2}}exp\{-\cfrac{1}{2\sigma^2}(x-u)^2\}\]

<p>을 pdf로 가지는 분포로, Multivariate version pdf는</p>

\[N(\mathbf{x}|\mathbf{u},\Sigma) = \cfrac{1}{(2\pi)^{D/2}}\cfrac{1}{|\Sigma|^{1/2}}exp\{-\cfrac{1}{2}(\mathbf{x} - \mathbf{u})^T\Sigma^{-1}(\mathbf{x} - \mathbf{u})\}\]

<p>의 형태를 가진다. (차원의 수가 $D$라고할 때) Bell Shaped Distribution으로 고등학교 확률과 통계 교과서에도 등장하는 분포이다.</p>

<p>여기서 $\mathbf{u}$ 와 $\Sigma$ 는 각각 $E(\mathbf{x})$ 과 $Var(\mathbf{x})$ 를 의미하는 모수이며, $\Sigma$ 는 그 특성상 Symmetric 하다.</p>

<p>이러한 정규분포를 이용한 정리에서 가장 중요한 정리 중 하나라고 할 수 있는 <em>Central Limit Theorem</em> 은, 특정 조건 하에, 표본이 어떠한 분포를 따르는지와 상관 없이 표본의 수가 증가함에 따라 표본의 평균 (<strong>표본 자체가 아니다</strong>)이 정규분포를 따른다는 정리이다. 이 정리를 이용하여 많은 통계적 문제를 정규분포를 이용해서 풀 수 있다.</p>

<p>Multivariate Normal의 p.d.f.에서 Exponential 항에 들어가 있는 quadratic form</p>

\[\bigtriangleup^2 = (\mathbf{x}-\mathbf{u})^T\Sigma^{-1}(\mathbf{x}-\mathbf{u})\]

<p>에서 $\bigtriangleup$은 <em>Mahalanobis Distance</em>로 불리며, 만약 $\Sigma$가 $I$ 라면 Euclidean Distance와 같은 의미를 갖게 된다. 2차원에서 예를 들면, <em>Mahalanobis Distance</em>는 다음을 가능하게 해준다.</p>

<p><img src="/assets/img/2021-09-21-prml-스터디-chap-2-2/KakaoTalk_Photo_2021-09-26-13-49-01.jpeg" alt="" title="Mahalanobis Dist" /></p>

<p>해당 그림에서 Euclidean Distnace를 기준으로 했다면 원점에서 x까지의 거리와 y까지의 거리는 서로 달랐겠지만, Mahalanobis Distance를 기준으로 한다면 동일하다. 이러한 특성으로 인해 2차원 정규분포의 p.d.f. 가 타원형의 contour로 나타날 수 있게 된다.</p>

<p>또한, $\Sigma$의 Eigenvalue Decomposition과 Change of Coordinate를 이용하여 Multivariate Normal p.d.f. 를</p>

\[p(y) = \prod_{j=1}^{D}\cfrac{1}{(2\pi\lambda_j)^{1/2}}exp\{-\cfrac{y_j^2}{2\lambda_j}\}\]

<p>로 표현할 수 있다. 여기서 $\lambda_j$와 $y_j$는 각각 Eigenvalue와 PC score를 의미한다. 이는 Multivariate Normal이 D개의 독립적인 Univariate Normal로 표현할 수 있다는 것을 의미한다.</p>

<p>이러한 Gaussian Distribution의 가장 큰 단점은 바로, 그 특성상 Unimodal (Single Maximum)하기 때문에, Multimodal (Multiple Maximum)한 데이터를 표현하기 적합하지 않다는 것이다. 이러한 점을 해결하기 위해 이후 Gaussian Mixture Model을 배우게 될 것이다.</p>

<h3 id="231-conditional-gaussian-distribution">2.3.1 Conditional Gaussian Distribution</h3>

<p>Gaussian 분포의 대표적인 특성 중 하나는 Conditional Distribution과 Marginal Distribution이 모두 다시 Gaussian 분포를 따른다는 것이다. 먼저 Conditional Distribution을 살펴보면,</p>

\[\begin {aligned} \mathbf{x} &amp;= \begin{pmatrix} \mathbf{x}_{a} \\\\ \mathbf{x}_{b} \end{pmatrix} \\\\ \mathbf{u} &amp;= \begin{pmatrix} \mathbf{u}_{a} \\\\ \mathbf{u}_{b} \end{pmatrix} \\\\
\Sigma &amp;= \begin{pmatrix} \Sigma_{aa} \Sigma_{ab} \\\\ \Sigma_{ba} \Sigma_{bb} \end{pmatrix} \end {aligned}\]

<p>로 partition을 했을 때 Conditional Distribution 
$p(\mathbf{x}_a|\mathbf{x}_b)$
는</p>

\[\begin {aligned} \mathbf{u}_{a|b} &amp;= \mathbf{u}_{a} + \Sigma_{ab}\Sigma_{bb}^{-1}(\mathbf{x}_{b} - \mathbf{u}_{b}) \\\\ \Sigma_{a|b} &amp;= \Sigma_{aa} - \Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba} \end {aligned}\]

<p>의 평균과 분산을 갖는 Gaussian Distribution을 따른다. 여기서 평균은 $\mathbf{x}_b$ 의 Linear Function으로 나타나고 분산은 $\mathbf{x}_a$ 와 무관함을 알 수 있는데, 이는 추후에 다룰 <em>Linear-Gaussian Model</em> 의 예시 중 하나로 볼 수 있다.</p>

<h3 id="232-marginal-gaussian-distribution">2.3.2 Marginal Gaussian Distribution</h3>

<p>위에서 언급했듯, Gaussian 분포의 Marginal Distribution 역시 Gaussian 분포를 따른다. 2.3.1 에서의 partition을 유지한다면, Marginal Distribution $p(\mathbf{x}_a)$ 는</p>

\[\begin {aligned} E[\mathbf{x}_a] &amp;= \mathbf{u}_a \\\\ Cov[\mathbf{x}_a] &amp;= \Sigma_{aa} \end {aligned}\]

<p>의 평균과 분산을 갖는 Gaussian Distribution을 따른다. 이는 굉장히 직관적이고 편한 결과임을 알 수 있다.</p>

<h3 id="233-bayes-theorem-for-gaussian-variables">2.3.3 Bayes’ theorem for Gaussian variables</h3>

<p>2.3.1 에서 Conditional Distribution 
$p(\mathbf{x}_a|\mathbf{x}_b)$
의 평균 은 
$\mathbf{x}_b$
의 Linear Function으로 나타나고 분산은 
$\mathbf{x}_a$
와 무관하다는 것을 밝혔다. 그렇다면 동일하게 Gaussian r.v. 들이</p>

\[\begin {aligned} p(\mathbf{x}) &amp;= N(\mathbf{x}|\mathbf{u},\Lambda^{-1}) \\\\ p(\mathbf{y|x}) &amp;= N(\mathbf{y}|A\mathbf{x} + \mathbf{b}, \mathbf{L}^{-1}) \end {aligned}\]

<p>로 주어진 상횡 (여기서 $\Lambda$ 와 $\mathbf{L}$ 은 분산의 역행렬인 Precision Matrix를 의미한다.) 에서의 Marginal Distribution $p(\mathbf{y})$ 와 Conditional Distribution 
$p(\mathbf{x|y})$
는 어떻게 나타날까? 이는 조건부 분포의 정의와 Bayes Theorem을 이용하여 구할 수 있는데, 그 결과는</p>

\[\begin {aligned} p(\mathbf{y}) &amp;= N(\mathbf{y}|A\mathbf{u} + \mathbf{b}, \mathbf{L}^{-1} + A\Lambda^{-1}A^T) \\
p(\mathbf{x|y}) &amp;= N(\mathbf{x}|\Sigma\{A^T\mathbf{L}(\mathbf{y}-\mathbf{b})+\Lambda\mathbf{u}\},\Sigma) \end {aligned}\]

<p>where</p>

\[\Sigma = (\Lambda + A^T\mathbf{L}A)^{-1}\]

<p>로 주어진다.</p>

<h3 id="234-maximum-likelihood-for-the-gaussian">2.3.4 Maximum Likelihood for the Gaussian</h3>

<p>Gaussian 분포에서도 MLE를 구할 수 있는데, likelihood function 에 log를 씌운 log-likelihood function를 구한 뒤, log-likelihood function를 최대로 해주는 값을 찾아주는 클래식한 접근을 사용한다.</p>

<p>먼저, log-likelihood는</p>

\[lnp(X|\mathbf{u},\Sigma) = -\cfrac{ND}{2}ln(2\pi) - \cfrac{N}{2}ln|\Sigma| - \cfrac{1}{2}\sum_{i=1}^{N}(\mathbf{x}_i-\mathbf{u})^T\Sigma^{-1}(\mathbf{x}_i-\mathbf{u})\]

<p>로 주어지는데, 여기서 Factorization Theorem을 통해 
<span>$\sum_{i=1}^{N} \mathbf{x}_i$</span>
와 
<span>$\sum_{i=1}^{N} \mathbf{x}_i\mathbf{x}_i^{T}$</span>
가 Sufficient Statistics 라는 것을 알 수 있다. 이후 해당 log-likelihood function를 최대화 해주는 $\mathbf{u}$ 와 $\Sigma$ 의 MLE를 찾아주면,</p>

\[\begin {aligned} \mathbf{u}_{ML} &amp;= \cfrac{1}{N}\sum_{i=1}^{N}\mathbf{x_i} \\\\ \Sigma_{ML} &amp;= \cfrac{1}{N}\sum_{i=1}^N(\mathbf{x}_i-\mathbf{u}_{ML})^T(\mathbf{x}_i-\mathbf{u}_{ML}) \end {aligned}\]

<p>의 값을 가진다는 것을 알 수 있다.</p>

<p>여기서, 정규분포의 MLE에서 잘 알려진 사실인 
<span>$\mathbf{u}_{ML}$</span>
은 unbiased estimator 이지만, 
<span>$\Sigma_{ML}$</span>
은 biased estimator 라는 것을 알 수 있다. 분산에 대한 unbiased estimator를 구하기 위해서는 $N$이 아닌 $(N-1)$로 나눠줘야 한다.</p>

<h3 id="235-sequential-estimation">2.3.5 Sequential estimation</h3>

<p>위에서 구한 평군에 대한 MLE의 식을 조금만 변형하면,</p>

\[\begin {aligned} \mathbf{u}_{ML}^{(N)} &amp;= \cfrac{1}{N}\sum_{i=1}^{N}\mathbf{x_i} \\ &amp;= \mathbf{u}_{ML}^{(N-1)} + \cfrac{1}{N}(\mathbf{x}_N - \mathbf{u}_{ML}^{(N-1)}) \end {aligned}\]

<p>라는 것을 알 수 있다. 즉, 새로운 데이터가 들어오는 대로 MLE의 추정치를 update하는 Sequential Estimation이 가능하다는 것이다. 이러한 Sequential Learning을 일반화 한 것이 <em>Robbins-Monro</em> Algorithm 이다.</p>

<p>Joint r.v. $(z,\theta)$ 가 있다고 하자. 이때, $z$의 조건부 기댓값은 $\theta$에 대한 function으로 나타나며,</p>

\[f(\theta) = E[z|\theta]\]

<p>로 쓸 수 있다. 이렇게 정의된 function을 <em>regression function</em> 이라고 부른다. 이제 목표는 
<span>$f(\theta^{*}) = 0$</span>
을 만족하는, $f$의 근 
<span>$\theta^{*}$</span>
를 찾는 것이다. 이때, z의 조건부 분산이 유한하다고 가정하고, WOLG (without loss of generality) 다음과 같이 근보다 작은 값에서는 음수 값을, 근보다 큰 값에서는 양수 값을 갖는 케이스를 생각하자.</p>

<p><img src="/assets/img/2021-09-21-prml-스터디-chap-2-2/f(theta).jpeg" alt="" title="f(theta)" /></p>

<p>그렇다면, <em>Robbins-Monro</em> Algorithm 은 Positive Sequence ${a_N}$ 을 통해 $\theta^*$ 에 대한 Sequential Estimation을 가능하게 해준다.</p>

\[\theta^{(N)} = \theta^{(N-1)} + a_{N-1}z(\theta^{(N-1)})\]

<p>여기서, $z(\theta^{(N)})$ 는 $\theta$가 $\theta^{(N)}$ 의 값을 가졌을 때의 z 값을 의미한다. 또한, ${a_N}$ 은 다음과 같은 3가지 조건을 만족해야 한다.</p>

<ol>
  <li>$\lim_{N \to \infty} a_N = 0$</li>
  <li>$\sum_{N=1}^{\infty}a_N = \infty$</li>
  <li>$\sum_{N=1}^{\infty}a^2_N &lt; \infty$</li>
</ol>

<p>이 모든 조건이 만족되면, 위의 Sequential Estimation이 실제 근으로 수렴한다는 것이 증명되어있다.</p>

<p>그럼 이제, <em>Robbins-Monro</em> Algorithm을 이용하여 MLE에 대한 Sequential Estimation을 해보자. MLE의 정의에 따라,</p>

\[\cfrac{\partial}{\partial\theta}\biggl\{\cfrac{1}{N}\sum_{i=1}^{N}ln\ p(\mathbf{x}_i|\theta)\biggr\}\biggl|_{\hat{\theta}} = 0\]

<p>임을 알 수 있는데, 여기서 합과 미분의 순서를 바꿔주고 $N$을 극한으로 보내면 대수의 법칙에 따라</p>

\[\lim_{N \to \infty}\cfrac{1}{N}\sum_{i=1}^{N}\cfrac{\partial}{\partial\theta}ln\ p(x_{i}|\theta) = E\biggl[\cfrac{\partial}{\partial\theta}ln\ p(x|\theta) \biggr]\]

<p>임을 알 수 있다. 즉, MLE를 구하는 과정 역시 regression function의 근을 찾는 것으로 생각할 수 있다는 것이다. 이에, <em>Robbins-Monro</em> Algorithm을 적용하면</p>

\[\theta^{(N)} = \theta^{(N-1)} + a_{N-1}\cfrac{\partial}{\partial\theta^{(N-1)}}ln\ p(x_N|\theta^{(N-1)})\]

<p>으로 MLE를 Sequential 하게 구할 수 있음을 알 수 있다.</p>

<h3 id="236-bayesian-inference-for-the-gaussian">2.3.6 Bayesian Inference for the Gaussian</h3>

<p>앞선 포스트에서 Bayesian Inference를 소개하며, Prior, Posterior 등의 개념을 설명한바 있다. Gaussian 분포에도 당연히 Bayesian Inference가 적용될 수 있는데, 첫번째로 분산이 알려진 상황에서 평균에 대한 베이즈 추론을 하는 경우를 생각해보자. (Univariate의 경우)</p>

<p>Conjugate Distribution이 되기 위한 2가지 조건을 생각해보면, 평균에 대한 베이즈 추론에서 사용하는 Prior는</p>

\[p(u) = N(u|u_0,\sigma_0^2)\]

<p>가 적합하다. 여기서 $u_0$ 와 $\sigma_0^2$ 는 임의의 hyperparameter로 볼 수 있다. 이후, Posterior 를 계산해보면,</p>

\[p(u|X) = N(u|u_N,\sigma_N^2)\]

<p>where</p>

\[\begin {aligned} u_N &amp;= \cfrac{\sigma^2}{N\sigma_0^2 + \sigma^2}u_0 + \cfrac{N\sigma_0^2}{N\sigma_0^2 + \sigma^2}{u_{ML}} \\\\ \cfrac{1}{\sigma_N^2} &amp;= \cfrac{1}{\sigma_0^2} + \cfrac{N}{\sigma^2} \end {aligned}\]

<p>가 된다.</p>

<p>여기서 앞에서 Binomial 분포와 Multinomial 분포에서 알 수 있었던 베이즈 추론의 일반적인 현상이 또 한번 나타나는데, 바로 N이 커지면 커질수록 Prior 의 영향력이 작아지고 MLE의 영량력이 커지는 방향으로 움직인다는 것이다. 또한, $\sigma_0^2$ 가 무한대로 가면 (Prior에서 $u_0$ 에 대한 확신이 없으면) $u_N$ 은 MLE로 수렴하고, $\sigma_N^2 = \sigma^2 / N$ 으로 나타남을 알 수 있다.</p>

<p>다음은 평균이 알려져있고 분산을 추정해야하는 경우를 생각해보자. 이때, 계산상 편의를 위해 분산의 역수인 Precision $(\lambda \equiv \cfrac{1}{\sigma^2})$ 을 추정하는 것으로 문제를 변경한다. 역시 Conjugate Distribution이 되기 위한 2가지 조건을 생각해보면, Prior로</p>

\[Gam(\lambda|a,b) = \cfrac{1}{\Gamma(a)}b^a\lambda^{a-1}exp(-b\lambda)\]

<p>가 적합하다는 것을 생각할 수 있다. (분산을 직접 추정하고 싶다면 <em>Inverse Gamma</em> 분포를 사용하면 된다.) 해당 Prior를 이용하여 Posterior를 계산해보면,</p>

\[p(\lambda|X) = Gam(\lambda|a_N,b_N)\]

<p>where</p>

\[\begin {aligned} a_N &amp;= a_0 + \cfrac{N}{2} \\\\ b_N &amp;= b_0 + \cfrac{N}{2}\sigma_{ML}^2 \end {aligned}\]

<p>가 된다.</p>

<p>$a_N$ 을 통해 Data Point 하나를 더 관측하는 것은 1/2 만큼의 영향을 준다는 것을 알 수 있는데, 이를 통해 $a_0$ 는 $2a_0$ 개의 ‘effective’ prior observation 으로 해석할 수 있다. 비슷하게, $b_N$ 을 통해 $b_0$ 를 variance $2b_0/2a_0 = b_0/a_0$ 을 가지는 $2a_0$ 개의 ‘effective’ prior observation 으로 인해 발생한 parameter로 해석할 수 있다. 앞서 Dirichlet Prior 에서도 이와 유사한 해석을 한적이 있는데, 사실 Normal과 Multinomial 분포는 모두 Exponential Family에 속하는 분포로 이러한 해석은 Exponential Family 에 속한 분포들에게 흔히 적용할 수 있는 해석이다.</p>

<p>이제, 평균과 분산을 모두 몰라서 동시에 추정해야하는 경우를 생각해보자. 이 경우 Conjugate의 2가지 조건을 만족하는 분포로</p>

\[p(u,\lambda) = N(u|u_0,(\beta\lambda)^{-1})Gam(\lambda|a,b)\]

<p>를 사용하는데, 이 분포는 Normal-gamma 혹은 Gaussian-gamma로 불리는 분포이다. (2개의 독립적인 Normal 분포와 Gamma 분포의 곱이 아니라, $u$의 precision이 $\lambda$ 의 linear function으로 주어진다라는 것에 주의하자)</p>

<p>이제, Multivariate Gaussian의 경우 각 prior를 Multivariate version으로 동일하게 확장해주면 된다. 첫번째 평균만을 위한 Prior는 Normal에서 Multivariate Normal로, 두번째 분산만을 위한 Prior는 Gamma 분포의 Multivariate version 인 Wishart Distribution으로, 마지막으로 평균과 분산 모두를 위한 Prior는 Normal-Wishart 혹은 Gaussian-Wishart 분포를 사용하면 된다.</p>

<h3 id="237-students-t-distribution">2.3.7 Student’s t-distribution</h3>

<p>2.3.6에서 Gaussian의 Precision을 위한 Prior는 Gamma 분포로 주어지는 것을 확인했다. 이때, Univariate Gaussian과 그 Precision의 Prior인 Gamma 분포의 joint p.d.f.에서 Precision을 적분해보자. 그럼 $x$ 의 Marginal Distribution은</p>

\[\begin {aligned} p(x|u,a,b) &amp;= \int_0^{\infty}N(x|u,\tau^{-1})Gam(\tau|a,b)d\tau \\\\ &amp;= \cfrac{b^a}{\Gamma(a)}\biggl({\cfrac{1}{2\pi}}\biggr)^{1/2}\biggl[b + \cfrac{(x-u)^{2}}{2}\biggr]^{-a-1/2}\Gamma(a+1/2) \end {aligned}\]

<p>으로 나타날 것이고, 여기서 $\nu = 2a$, $\lambda = a/b$ 로 두면,</p>

\[St(x|u,\lambda,\nu) = \cfrac{\Gamma(\nu/2 + 1/2)}{\Gamma(\nu/2)}\biggl(\cfrac{\lambda}{\pi\nu}\biggr)^{1/2}\biggl[1 + \cfrac{\lambda(x-u)^2}{\nu}\biggr]^{-\nu/2-1/2}\]

<p>의 p.d.f.를 갖는 Student’s t-distribution이 나타난다. ($\lambda =1,u=0$ 이면 우리가 흔히 아는 t-distribution이 된다.)</p>

<p>여기서 $\nu$ 는 degree of freedom 으로 불리는 parameter 인데, df가 무한대로 가면 
<span>$St(x|u,\lambda,\nu)$</span>
는 
<span>$N(x|u,\lambda^{-1})$</span>
로 분포수렴한다는 것은 유명한 사실이다.</p>

<p>Student’s t-distribution은 그 생성 방법으로부터 동일한 평균 $u$ 를 가졌지만 다른 Precision $\tau$ 을 가지는 정규분포를 무한개 더한 것으로 이해할 수 있는데, (적분을 함수간의 내적으로 해석하면, 평균 $\mu$, Precision $\tau$ 를 가지는 정규분포들을 0부터 $\infty$ 까지 $\tau$의 확률을 weight로 주어 Sum 해준것으로 볼 수 있다. ) Student’s t-distribution은 infinite mixture of Gaussian으로 해석할 수 있다. 그 결과 Student’s t-distribution은 일반적으로 Gaussian 분포보다 longer tail을 갖게 되고, Outlier 몇개에 크게 영향을 받지 않는 Robustness 라는 특성을 가지게 된다. 이로인해 Normal 분포 대신 Student’s t-distribution을 사용하는 Robust Regression도 존재한다.</p>

<p>Multivariate Gaussian이 존재하듯 Student’s t-distribution 도 Multivariate version이 존재하는데, Univariate Gaussian이 아닌 Multivariate Gaussian의 Sum으로 생성할 수 있으며</p>

\[St(\mathbf{x}|\mathbf{u},\Lambda,\nu) = \cfrac{\Gamma(D/2 + \nu/2)}{\Gamma(\nu/2)}\cfrac{|\Lambda|^{1/2}}{(\pi\nu)^{D/2}}\biggl[1 + \cfrac{\bigtriangleup^2}{\nu}\biggr]^{-D/2 -\nu/2}\]

<p>의 p.d.f. 를 가진다. 여기서 $D$ 는 $\mathbf{x}$ 의 Dimension을, $\bigtriangleup^2$ 은 squared Mahalanobis distance를 의미한다.</p>

<p>Multivariate Student’s t-distribution 의 평균과 공분산은 다음과 같다.</p>

\[\begin {aligned}E[\mathbf{x}] &amp;= \mathbf{u} \\\\ cov[\mathbf{x}] &amp;= \cfrac{\nu}{(\nu - 2)}\Lambda^{-1} \end {aligned}\]

<p>(단, 평균은 $\nu &gt; 1$ 인 경우, 분산은 $\nu &gt; 2$ 인 경우 정의된다.)</p>

<h3 id="238-periodic-variables">2.3.8 Periodic variables</h3>

<p>때때로, 주기성을 가지는 변수에 대한 확률 모델을 construct 해야하는 경우가 있다. 예를 들어 방향, 시간 등의 값을 갖는 변수는 그 특성상 주기성을 가질 수 있다. 특히, 공간과 시간을 다루는 Spatio-Temporal Statistics에서는 이러한 변수를 다뤄야 할 일이 많이 발생한다. 이번 절에서는 이러한 주기성을 가지는 확률변수를 위한 분포인 Von Mises Distribution을 Gaussian 분포를 이용하여 어떻게 생성해내는지 다룰 것이다. (이번 절에서는 Univariate 한 경우만 다룬다.)</p>

<p>주기성을 다루자면 자연스럽게 $2\pi$의 주기를 가지는 분포 $p(\theta)$를 생각할 수 있다. 해당 $p(\theta)$는 3가지 조건을 만족해야 한다.</p>

<ol>
  <li>$p(\theta) \geq 0$</li>
  <li>$\int_0^{2\pi}p(\theta) = 1$</li>
  <li>$p(\theta + 2\pi) = p(\theta)$</li>
</ol>

<p>위 3가지 조건을 만족하는 분포를 생성하기 위해 먼저 평균 $\mathbf{u} = (u_1,u_2)$를 가지고, 공분산 행렬 $\Sigma = \sigma^2I$를 가지는 2차원 정규분포를 생각해보자. 그렇다면, 해당 분포는 2차원 공간에서 원 모양의 contour를 가질 것이고, 이 중 고정된 반지름을 가지는 원에 걸치는 부분만 생각한다면 그 부분의 분포는 당연히 주기성을 띄게 될 것이다. 분포의 p.d.f. 를 구하기 위해 먼저 $(x_1,x_2)$ 좌표를 극좌표 $(r,\theta)$로 변환하면 기초 미적분에서 배우듯이 $x_1 = rcos\theta$ , $x_2 = rsin\theta$ 로 변환된다. 이에 따라, 평균 $\mathbf{u}$ 또한 $\mathbf{u_1} = r_0cos\theta_0$, $\mathbf{u_2} = r_0sin\theta_0$ 로 변환될 수 있다.</p>

<p>이제 2차원 정규분포의 p.d.f. 를 극좌표로 변환하고, 위에서 말한대로 고정된 반지름 $r =1$ 인 경우만 생각하면 주기성을 가지는 분포를 만들어낼 수 있다. 해당 과정을 그림으로 보면 다음과 같다.</p>

<p><img src="/assets/img/2021-09-21-prml-스터디-chap-2-2/Figure%201.jpeg" alt="" title="Figure 1" /></p>

<p><img src="/assets/img/2021-09-21-prml-스터디-chap-2-2/Figure%202.jpeg" alt="" title="Figure 2" /></p>

<p>첫번째 그림에서, $\overline{\mathbf{x}} = (\overline{r}cos\overline{\theta},\overline{r}sin\overline{\theta})$ 으로 나타나는 것을 알 수 있고,</p>

\[\begin {aligned}
\overline{r}cos\overline{\theta} = \cfrac{1}{N}\sum_{i=1}^{N}cos\theta_i &amp;&amp;
\overline{r}sin\overline{\theta} = \cfrac{1}{N}\sum_{i=1}^{N}sin\theta_i 
\end {aligned}\]

<p>를 통해서,</p>

\[\overline{\theta} = tan^{-1}\biggl\{\cfrac{\sum_isin\ \theta_i}{\sum_icos\ \theta_i}\biggr\}\]

<p>임을 알 수 있는데, 이는 곧 Von Mises 분포의 $\theta_{0}^{ML}$ 과 같은 값이라는 것이 곧 밝혀질 것이다.</p>

<p>그리고, 두번째 그림에서 Gaussian의 Exponential Part 만 고려하면 (실제 변수는 Exponential Part 에만 존재하므로)</p>

\[\begin {aligned} -\cfrac{(x_1 - u_1)^2 + (x_2-u_2)^2}{2\sigma^2} &amp;= -\cfrac{1}{2\sigma^2}\{(r\cos\theta - r_0\cos\theta_0)^2+(r\sin\theta - r_0\sin\theta_0)^2\} \\\\ &amp;\stackrel{r=1}{=} \cfrac{r_0}{\sigma^2}cos(\theta - \theta_0) + const \end {aligned}\]

<p>로 정리된다. (여기서 초점은 변수 변환 그 자체가 아니라 주기성을 띄는 새로운 p.d.f. 를 만드는 것이기에 자코비안도 무시한다.) 이제 $m = r_0/\sigma^2$로 정의하고 위의 2번째 조건을 만족하기 위해 Normalizing Constant를 넣어주면,</p>

\[p(\theta|\theta_0,m) = \cfrac{1}{2{\pi}I_0(m)}exp\ \{m\cos(\theta - \theta_0)\}\]

<p>로 나타는데, 이 p.d.f. 가 Von Mises 분포의 p.d.f. 이며, $\theta_0$ 는 평균을 나타내는 parameter이며, $m$ 은 Concentration parameter로 Gaussian에서 Precision에 대응된다.</p>

<p>여기서, $I_0(m) = \int_0^{2\pi}exp\ {m\ cos\theta}d\theta$ 로 zeroth-order Bessel function of the first kind 이다.</p>

<p>MLE 추정을 위해 log-likelihood function을 계산하고 $\theta_0$ 와 $m$으로 미분한 값을 0으로 두면, $\theta_0$의 MLE는</p>

\[\theta_0^{ML} = tan^{-1}\biggl\{\cfrac{\sum_{i}sin\theta_{i}}{\sum_{i}cos\theta_{i}}\biggr\}\]

<p>으로 나타나고, (위에서 언급한 $\overline{\theta}$ 와 동일한 값이 된다.) $m$의 MLE는</p>

\[A(m_{ML}) = \cfrac{1}{N}\sum_{i = 1}^{N}cos(\theta_{i} - \theta_0^{ML})\]

<p>where</p>

\[A(m) = \cfrac{I_1(m)}{I_0(m)}\]

<p>로 나타난다. ($I_0’(m) = I_1(m)$ 을 이용)</p>

<p>여기서, 삼각함수 공식 $cosA\ cosB + sinA\ sinB = cos(A-B)$ 를 적용하면,</p>

\[A(m_{ML}) = \biggl(\cfrac{1}{N}\sum_{i =1}^{N}cos\theta_i\biggr)cos\theta_0^{ML} + \biggl(\cfrac{1}{N}\sum_{i =1}^{N}sin\theta_i\biggr)sin\theta_0^{ML}\]

<p>로 나타낼 수 있고 $\overline{r}$, $\overline{\theta}$ 를 이용하여</p>

\[A(m_{ML}) = \overline{r}\]

<p>로 정리됨을 알 수 있다. 이제 $A^{-1}$ 를 양측에 취해주면 $m_{ML}$ 을 구할 수 있다.</p>

<h3 id="239-mixture-of-gaussians">2.3.9 Mixture of Gaussians</h3>

<p>이전에, Gaussian 분포는 Unimodal 하기 때문에 Multimodal 한 데이터를 표현하기 위해 Mixture of Gaussians를 배워야 한다고 했었다. Mixture Model은 여러 분포의 Linear Combination을 의미하는데, Mixture of Gaussians는 그 중에서 다음과 같이 여러 Gaussian 분포를 선형결합한 형태이다.</p>

\[p(\mathbf{x}) =  \sum_{k=1}^{K}\pi_kN(\mathbf{x}|\mathbf{u}_k,\Sigma_k)\]

<p>여기서, 각 
<span>$N(\mathbf{x}|\mathbf{u}_k,\Sigma_k)$</span>
은 <em>component</em>, 
<span>$\pi_k$</span>
는 <em>mixing coefficient</em> 로 불린다. 이렇게 형성된 Mixture of Gaussians를 시각화한 예는 다음과 같다.</p>

<p>Mixing Coefficient $\pi_k$ 는 Normalization을 위해서 다음 2개 조건을 만족해야 한다.</p>

<ol>
  <li>$\sum_{k = 1}^{K}\pi_k = 1$</li>
  <li>$0 \leq \pi_k \leq1$</li>
</ol>

<p>이는 확률값이 가져야 하는 조건과 흡사한데, 실제로</p>

\[p(\mathbf{x}) = \sum_{k=1}^{K}p(k)p(\mathbf{x}|k)\]

<p>라는 사실에서 알 수 있듯 
<span>$\pi_k$</span>는
k 번째 component를 뽑을 prior probability $p(k)$, 
<span>$N(\mathbf{x}|\mathbf{u}_k,\Sigma_k)$</span>
는 k에 조건부가 걸린 $\mathbf{x}$의 확률 
$p(\mathbf{x}|k)$
로 이해할 수 있다. 이에, Mixture of Gaussian을 생성하는 Sampling Simulation은 각 component에서 $\pi_k$에 의해 정해진 확률대로 sample을 뽑는 방식으로 진행된다. 또한, 반대로 데이터가 주어졌을 때 해당 데이터가 어느 component에서 나왔는지에 대한 확률인 <em>responsibilities</em> (
<span>$\gamma_k(\mathbf{x}) \equiv p(k|\mathbf{x})$</span>
) 역시 중요한 의미를 가지는데, 이는 이후 클러스터링 기법 중 하나인 GMM (Gaussian Mixture Model)과 큰 관계가 있다.</p>

<p>Mixture of Gaussian의 MLE는 단일 Gaussian에 비해 구하기가 매우 힘든데, 보통은 나중에 다룰 EM Algorithm을 통해 구한다.</p>]]></content><author><name>cwyoon96</name></author><category term="PRML 스터디" /><category term="Machine Learning" /><category term="PRML" /><summary type="html"><![CDATA[(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)]]></summary></entry></feed>