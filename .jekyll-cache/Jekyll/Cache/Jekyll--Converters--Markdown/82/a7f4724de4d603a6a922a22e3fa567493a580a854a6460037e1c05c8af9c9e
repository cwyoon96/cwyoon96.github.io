I"<p>(본 내용은 독자가 학부 확률론 및 수리통계학 지식이 있다는 가정 하에 작성되었습니다.)</p>

<p>PRML 3.4절의 주제는 Bayesian Model Comparison이다. 3.4절에서는 굉장히 conceptual 한 내용이 나와서 한번에 이해하기 쉽지 않을 수 있지만, 3.5절에서 더 구체적 예시를 통해 설명하니 쉽게 이해가 되지 않아도 너무 걱정하지 말자.</p>

<h2 id="34-bayesian-model-comparison">3.4 Bayesian Model Comparison</h2>

<p>이번 절에서는 베이지안 관점에서 모델 (혹은 하이퍼파라미터)를 선택하는 방법에 대해 다룬다. 기본적으로, 모델 선택에는 Cross Validation과 같은 방법이 많이 사용되지만, 해당 방법은 Validation Set을 따로 남겨둬야해서 전체 데이터를 Training 과정에 사용할 수 없다는 단점이 있다. 반면에 Bayesian Model Comparison은 Train Set 만으로도 Model Comparison을 가능하게 해준다.</p>

<p>먼저, 비교할 모델의 Set이 ${M_i}$ where $i = 1,…,L$ 로 존재한다고 하자. 여기서 각 모델은 관측된 데이터에 대한 확률분포로 해석할 수 있고, 데이터가 이 중 하나의 모델에서 생성되었지만 어떤 모델에서 나온 것인지 알 수 없는 상황이라 볼 수 있다. 이런 불확실성은 prior probability distribution $p(M_{i})$로 나타낼 수 있고 (각 모델에 대한 기본적 선호도를 나타낸다고 볼 수 있다), 주어진 데이터를 통해 posterior를 구해야할 것이다. 이때 posterior distribution은</p>

\[p(M_{i}|D) \propto p(M_{i})p(D|M_{i})\]

<p>으로 주어진다. 이때, 단순하게 prior는 모두 동일한 케이스를 가정하자.</p>

<p>그럼, 주목해야할 항은 <em>model evidence</em> 혹은 <em>marginal likelihood</em>로 불리는 
<span>$p(D|M_{i})$</span>
이다. 이는 주어진 모델에 대해서 각 데이터의 확률분포를 나타낸다고 생각할 수 있다.2개 모델의 model evidence 간의 비율 
<span>$p(D|M_{i})/p(D|M_{j})$</span>
는 <em>Bayes Factor</em>라 불린다.</p>

<p>이제 posterior distribution을 이용해서 predictive distribution</p>

\[p(t|\mathbf{x},D) = \sum_{i = 1}^{L}p(t|\mathbf{x},M_{i},D)p(M_{i}|D)\]

<p>을 구할 수 있다. 이는 <em>mixture distribution</em>의 일종으로, 각 모델의 posterior를 weight로 사용하여 predictive distribution을 평균낸 것으로 이해할 수 있다. 하지만 가장 쉬운 방법은 가장 가능성이 높은 모델 하나만 사용하는 것이기에 주로 <em>Model Selection</em>을 진행한다.</p>

<p>다시 Model Evidence에 대한 이야기로 돌아와 모델이 parameter $\mathbf{w}$에 의해 결정되는 케이스를 생각해보자. 그렇다면 model evidence는</p>

\[p(D|M_{i}) = \int p(D|\mathbf{w},M_{i})p(\mathbf{w}|M_{i})d\mathbf{w}\]

<p>로 주어진다. Sampling 관점에서는 model evidence는 prior에 의해 random으로 생성된 parameter로 정의된 모델에서 해당 data set $D$를 generaete할 확률로 이해할 수 있다. 또한, parameter에 대한 posterior를 계산할 때,</p>

\[p(\mathbf{w}|D,M_{i}) = \cfrac{p(D|\mathbf{w},M_{i})p(\mathbf{w}|M_i)}{p(D|M_i)}\]

<p>으로 계산되기에 model evidence가 normalizing term으로 쓰인다는 것도 흥미로운 지점으로 생각할 수 있다.</p>

<p>Parameter $w$에 (dimension이 1인 단순한 경우를 가정) 대한 적분을 통해 model evidence에 대한 더 흥미로운 insight를 얻을 수 있다. Parameter의 posterior distribution은 
<span>$p(D|w)p(w)$</span> 
에 비례하는데 (Model notation 생략), posterior 분포가 
<span>$w_{MAP}$</span>에 굉장히 몰려있고, 그 width를 
<span>$\triangle w_{posterior}$</span>이라 가정하자. 또한, prior가 flat한 형태에 width가 
<span>$\triangle w_{prior}$</span>이라 가정하면 (
<span>$p(w) = 1/\triangle w_{prior}$</span>
),</p>

\[p(D) = \int p(D|w)p(w)dw \approx p(D|w_{MAP})\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\]

<p>으로 둘 수 있고, 양변에 $log$를 취하면,</p>

\[ln\ p(D) \approx p(D|w_{MAP}) + ln\bigg(\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\bigg)\]

<p>으로 주어진다.</p>

<p><img src="/assets/img/2021-11-19-prml-스터디-chap-3-4/Figure%203.12.png" alt="" /></p>

<p>첫번째 항은 가장 가능성이 높은 parameter value에 기반한 data fit을 의미하며, prior가 flat 하다면 이는 log likelihood와 동일하다. 두번째 항은 Model Complexity에 따른 penalty 항으로 이해할 수 있다. $\triangle w_{posterior} &lt; \triangle w_{prior}$ 이면 두번째 항은 negative value를 가지고, $\triangle w_{posterior} / \triangle w_{prior}$ 비율이 작아질 수록 magnitude가 커지게 된다. 즉, parameter가 posterior distribution의 데이터에 더 fitted 되어있을 수록 penalty term이 커지게 된다.</p>

<p>이제 모델이 $M$개의 parameter를 가지고 있고, 모든 parameter가 동일한 $\triangle w_{posterior} / \triangle w_{prior}$ 비율을 가지고 있다고 가정하자. 그렇다면,</p>

\[ln\ p(D) \approx p(D|\mathbf{w}_{MAP}) + M\ ln\bigg(\cfrac{\triangle w_{posterior}}{\triangle w_{prior}}\bigg)\]

<p>으로 나타낼 수 있다. Model complexity가 높아질 수록 첫번째 항은 줄어들겠지만, 두번째 항은 M에 의존하기 때문에 더욱 커질 것이며 maximum evidence로 결정되는 optimal model complexity는 이 2개 항의 trade-off 사이에서 주어지게 된다.</p>

<p>이제, marginal likleihood (model evidence)를 통해 어떻게 intermediate complexity 모델이 선택될 수 있는지 살펴보자. 아래의 그림에서 x 축은 가능한 데이터셋의 one-dimensional representation이며 특정 point는 특정한 데이터셋을 의미한다고 생각할 수 있다.</p>

<p><img src="/assets/img/2021-11-19-prml-스터디-chap-3-4/Figure%203.13-01.png" alt="" /></p>

<p>이제 각 Model Complexity에 따른 $p(D)$의 형태를 생각해보자. 가장 간단한 모델인 $M_1$에서 데이터가 랜덤하게 생성된다고 생각하면, 생성된 데이터셋들의 분산은 상대적으로 작을 것이며 서로 비슷한 모양을 가질 것이다. 반대로, 모델이 복잡해질 수록 생성될 수 있는 형태의 데이터셋이 다양해질 것이고, $M_3$처럼 더 Sparse 한 Distribution을 가지게 될 것이다. 이 때, 
<span>$p(D|M_i)$</span>
는 Normalize 되어야하기 때문에, 그림에서 처럼 특정 데이터셋 포인트에서는 intermediate complexity model의 model evidence가 가장 커질 수 있는 것이다.</p>

<p>Bayesian Model Comparison의 기본적인 가정은 실제로 데이터가 현재 고려 중인 모델 중 하나에서 생성되었다는 것이다. 해당 가정이 사실이라고 했을 때, Bayesian Model Comparison은 평균적으로 correct model을 선택할 수 있게 해준다. 2개의 Model $M_1,M_2$ 가 있다고 하고, correct model이 $M_1$인 경우를 생각하자. Bayes factor를 데이터셋의 실제 분포 (correct model)로 평균을 내면</p>

\[\int p(D|M_1)ln\cfrac{p(D|M_1)}{p(D|M_2)}dD\]

<p>로 나타날 것이다. 이는 <em>Kullback-Leibler</em> <em>divergence</em> 의 형태로 항상 양수 값을 가지며 2개의 distribution이 동일한 경우에만 0의 값을 가진다. 즉, 평균적으로 Bayes factor는 항상 correct model을 찾아내는 것이다.</p>

<p>Bayesian Model Comparison은 over-fitting 문제를 피하고 train data 만으로 비교를 가능하게 해주지만, 여전히 다른 머신러닝 문제처럼 여러 가정이 필요하고 해당 가정이 사실이 아니라면 그 결과를 믿을 수 없게 된다. 이에, 실제 문제에있어서는 test set 데이터를 따로 두고 최종 system의 performance를 체크하는 것이 현명할 것이다.</p>
:ET