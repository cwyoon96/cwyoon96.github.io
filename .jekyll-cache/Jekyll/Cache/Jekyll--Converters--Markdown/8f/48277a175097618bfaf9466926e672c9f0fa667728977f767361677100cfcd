I"65<h3 id="555-training-with-transformed-data">5.5.5 Training with transformed data</h3>

<p>Model에 transformation invariance를 유도하는 또 다른 방법으로 당연히 transformed 된 데이터를 함께 학습에 이용하는 것을 생각할 수 있다. 이번 절에서는 해당 방법이 5.5.4절에서 다뤘던 tangent propagation과 매우 긴밀하게 연결되어 있다는 것을 보일 것이다.</p>

<p>5.5.4절에서와 같은 transformation을 가정하고, sum-of-square error function을 사용한다고 하면 untransformed inputs를 이용한 이론적인 error function은</p>

\[E = \cfrac{1}{2}\int \int \{y(\mathbf{x})-t\}^{2} p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt\]

<p>로 주어진다. (single output 가정)</p>

<p>이제 $\xi$가 distribution $p(\xi)$ (zero mean with samll variance)에서 draw 되었다고 가정하면, 확장된 error function은</p>

\[\tilde{E} = \cfrac{1}{2} \int \int \int \{y(\mathbf{s}(\mathbf{x},\xi)) - t\}^2 p(t|\mathbf{x})p(\mathbf{x})p(\xi)d\mathbf{x}dtd\xi\]

<p>로 쓸 수 있다.</p>

<p>이때, tranformation function $\mathbf{s}$에 대한 Taylor expansion을 통해</p>

\[\begin{aligned}
\mathbf{s}(\mathbf{x},\xi) &amp;= \mathbf{s}(\mathbf{x},0) + \left. \xi \cfrac{\partial}{\partial \xi} \mathbf{s}(\mathbf{x},\xi)\right|_{\xi = 0} + \left. \cfrac{\xi^2}{2} \cfrac{\partial^2}{\partial \xi^2} \mathbf{s}(\mathbf{x},\xi)\right|_{\xi = 0} + O(\xi^3) \\
&amp;= \mathbf{x} + \xi \boldsymbol{\tau} + \cfrac{1}{2}\xi^2\boldsymbol{\tau'} + O(\xi^3)
\end{aligned}\]

<p>로 쓸 수 있어</p>

\[y(\mathbf{s}(\mathbf{x},\xi)) = y(\mathbf{x}) + \xi \boldsymbol{\tau}^{T} \bigtriangledown y(\mathbf{x}) + \cfrac{\xi^2}{2}\bigg[ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \bigg] + O(\xi^3)\]

<p>로 model function을 쓸 수 있게 된다. 이제 이를 error function에 plug-in 하면</p>

\[\begin{aligned}

\tilde{E} &amp;= \cfrac{1}{2} \int \int \{ y(\mathbf{x}) - t \}^2p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt \\
&amp;+ \mathbb{E}[\xi] \int \int \{ y(\mathbf{x}) - t \} \boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x})p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt \\
&amp;+ \mathbb{E}[\xi^2] \int \int \bigg[ \{y(\mathbf{x}) - t\}\cfrac{1}{2} \big\{ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \big\} + \\ &amp;(\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 \bigg]p(t|\mathbf{x})p(\mathbf{x})d\mathbf{x}dt + O(\xi^3)

\end{aligned}\]

<p>로 주어진다. 이때, 가정에 따라 $\mathbb{E}[\xi] = 0$ 임을 이용하고 $\mathbb{E}[\xi^2]$를 $\lambda$로 denote 하면 5.5.4절에서 보았던</p>

\[\tilde{E} = E + \lambda \Omega \ \ \ \ \ \ \ \ \ - (*)\]

<p>where</p>

\[\begin{aligned}

\Omega = &amp;\int \bigg[ \{y(\mathbf{x}) - \mathbb{E}[t|\mathbf{x}]\}\cfrac{1}{2} \big\{ (\boldsymbol{\tau'})^T \bigtriangledown y(\mathbf{x}) + \boldsymbol{\tau}^T \bigtriangledown \bigtriangledown y(\mathbf{x}) \boldsymbol{\tau} \big\} \\ &amp;+ (\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 \bigg]p(\mathbf{x})d\mathbf{x}

\end{aligned}\]

<p>의 형태가 됨을 알 수 있다. ($t$로 적분하고 $O(\xi^3)$ omit)</p>

<p>앞서 1절에서 sum-of-square error를 최소한으로 하는 것은 
$\mathbb{E}[t|\mathbf{x}]$
임을 밝혔다. 이에 위 (*)식으로부터 reuglarized error를 최소한으로 하는 network function은</p>

\[y(\mathbf{x}) = \mathbb{E}[t|\mathbf{x}] + O(\xi)\]

<p>임을 알 수 있고, $\xi$의 최고차항을 기준으로 regularizer의 first term이 사라져</p>

\[\Omega = \cfrac{1}{2} \int (\boldsymbol{\tau}^T \bigtriangledown y(\mathbf{x}))^2 p(\mathbf{x})d\mathbf{x}\]

<p>로 주어져 5.5.4절에서 보았던 tangent propagation regularizer와 완벽히 일치함을 알 수 있다.</p>

<h2 id="57-bayesian-neural-networks">5.7 Bayesian Neural Networks</h2>

<p>현재까지는 MLE에 기반하여 Neural Network를 공부하였지만, 5.7절에서는 Bayesian Neural Network를 다룬다. Neural Network는 그 자체의 nonlinearity로 인해 Linear regression과 다르게 Bayesian treatment를 그대로 적용하기 어렵다. 이에 이번 절에서는 Laplace approximation을 통해 Bayesian Neural Network를 어떻게 implement 할 수 있는지 살펴볼 것이다.</p>

<h3 id="571-posterior-parameter-distribution">5.7.1 Posterior parameter distribution</h3>

<p>먼저 single output regression 문제를 생각해보자. 이때,</p>

\[p(t|\mathbf{x},\mathbf{w},\beta) = N(t|y(\mathbf{x},\mathbf{w}),\beta^{-1})\]

<p>로 가정한다. 또한, 이전 Bayesian linear regression에서 처럼</p>

\[p(\mathbf{w}|\alpha) = N(\mathbf{w}|\mathbf{0},\alpha^{-1}\mathbf{I})\]

<p>로 가정하자. i.i.d. 한 $N$개의 observation에 대해서 target values를 $\mathbf{D} = {t_1,…,t_N}$로 notate 하면 최종적인 posterior distribution은 자연스럽게</p>

\[p(\mathbf{w}|\mathbf{D},\alpha,\beta) \propto p(\mathbf{w}|\alpha)p(\mathbf{D}|\mathbf{w},\beta)\]

<p>로 주어진다. 하지만, $y(\mathbf{x},\mathbf{w})$가 $\mathbf{w}$에 대해 nonlinear하게 dependent하기 때문에 posterior distribution은 더 이상 Gaussian distribution을 따르지 않게 되고 Laplace approximation을 통해 Gaussian approximation을 진행해야한다.</p>

\[ln \ p(\mathbf{w}|\mathbf{D}) = -\cfrac{\alpha}{2} \mathbf{w}^{T}\mathbf{w} - \cfrac{\beta}{2} \sum_{n=1}^{N}\{y(\mathbf{x}_n, \mathbf{w})- t_n\}^2 + \text{const}\]

<p>로 주어지는 log posterior를 maximize 하는 $\mathbf{w}_{MAP}$를 앞서 소개한 optimization 방법들을 통해 구했다고 하자. 이제 negative log posterior의 second derivative matrix를 구해야 한다. 이는</p>

\[\mathbf{A} = -\bigtriangledown \bigtriangledown ln \ p(\mathbf{w}|\mathbf{D},\alpha,\beta) = \alpha \mathbf{I} + \beta \mathbf{H}\]

<p>로 구해지는데, 여기서 $\mathbf{H}$는 sum-of-square를 $\mathbf{w}$로 2차 미분한 Hessian이다.</p>

<p>이제 4장에서 다룬 Laplace approximation을 통해</p>

\[q(\mathbf{w}|\mathbf{D}) = N(\mathbf{w}|\mathbf{w}_{MAP},\mathbf{A}^{-1})\]

<p>로 posterior를 approximate 할 수 있다.</p>

<p>이제 predictive distribution</p>

\[p(t|\mathbf{x},\mathbf{D}) = \int p(t|\mathbf{x},\mathbf{w})q(\mathbf{w}|\mathbf{D})d\mathbf{w}\]

<p>를 구할 수 있는데, 문제는 Gaussian approximation을 한 이후에도 $y(\mathbf{x},\mathbf{w})$의 nonlinearity로 인해 해당 적분이 intractable 하다는 것이다. 이에 posterior distribution이 작은 분산을 가지고 있다고 가정하고, Taylor expansion을 통해</p>

\[y(\mathbf{x},\mathbf{w}) \simeq y(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{g^{T}}(\mathbf{w} - \mathbf{w}_{MAP})\]

<p>where</p>

\[\mathbf{g} = \bigtriangledown_{\mathbf{w}}y(\mathbf{x},\mathbf{w})|_{\mathbf{w} = \mathbf{w}_{MAP}}\]

<p>로 linear term만 남기는 approximation을 생각한다. 이제 linear-Gaussian model로서 
$p(t|\mathbf{w})$
의 mean이 
$\mathbf{w}$
에 대해 linear한 형태</p>

\[p(t|\mathbf{x},\mathbf{w},\beta) \simeq N(t|y(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{g^{T}}(\mathbf{w} - \mathbf{w}_{MAP}), \beta^{-1})\]

<p>가 될 것이며, 2장에서의 linear-Gaussian model에 대한 정리를 이용해</p>

\[p(t|\mathbf{x},\mathbf{D},\alpha,\beta) = N(t|y(\mathbf{x},\mathbf{w}_{MAP}), \sigma^2(\mathbf{x}))\]

<p>where</p>

\[\sigma^2(\mathbf{x}) = \beta^{-1} + \mathbf{g}^{T}\mathbf{A}^{-1}\mathbf{g}\]

<p>로 predictive distribution을 구할 수 있다.</p>

<h3 id="572-hyperparameter-optimization">5.7.2 Hyperparameter optimization</h3>

<p>지금까지는 $\alpha,\beta$가 알려져있고 고정되어있다고 가정하였다. 하지만, 3.5절에서 다뤘던 것처럼 해당 hyperparameter에 대해 최적의 값을 찾을 수 있다. Hyperparameter에 대한 evidence는</p>

\[p(\mathbf{D}|\alpha,\beta) = \int p(\mathbf{D}|\mathbf{w},\beta)p(\mathbf{w}|\alpha)d\mathbf{w}\]

<p>로 구할 수 있고, 역시 Laplace approximation을 통해</p>

\[ln \ p(\mathbf{D}|\alpha,\beta) \simeq -E(\mathbf{w}_{MAP}) - \cfrac{1}{2} ln |\mathbf{A}| + \cfrac{W}{2} ln \ \alpha + \cfrac{N}{2} ln \ \beta - \cfrac{N}{2} ln(2\pi)\]

<p>where</p>

\[E(\mathbf{w}) = \cfrac{\alpha}{2} \mathbf{w}^{T}\mathbf{w} + \cfrac{\beta}{2} \sum_{n=1}^{N}\{y(\mathbf{x}_n, \mathbf{w})- t_n\}^2\]

<p>를 구할 수 있는데, 이는 3장에서의 linear regression model에서와 동일한 형태임을 알 수 있다. 이에 3.5절에서와 마찬가지로 최적의 $\alpha$는</p>

\[\alpha = \cfrac{\gamma}{\mathbf{w}_{MAP}^{T}\mathbf{w}_{MAP}}\]

<p>where</p>

\[\gamma = \sum_{i = 1}^{W}\cfrac{\lambda_i}{\alpha + \lambda_i}\]

<p>로 구할 수 있다. 여기서 $\lambda_i$는 sum-of-squares error function을 2번 미분하여 $\mathbf{w} = \mathbf{w}_{MAP}$에서 evaluate한 Hessian matrix $\mathbf{H}$의 eigenvalue로,</p>

\[\beta \mathbf{H}\mathbf{u}_{i} = \lambda_{i}\mathbf{u}_i\]

<p>에서 주어진 value이다.</p>

<p>Linear regression에서는 이 값이 exact한 값으로 나왔지만, nonlinear한 neural network에서는 $\alpha$가 변화함에 따라 $\mathbf{H}$도 변화한다. 따라서 위와 같은 결과는 $\lambda_i$를 $\alpha$로 미분한 항을 무시한 것으로 봐야한다.</p>

<p>또한, 최적의 $\beta$는 3.5절에서 처럼</p>

\[\cfrac{1}{\beta} = \cfrac{1}{N - \gamma} \sum_{n = 1}^{N}\{ y(\mathbf{x}_n,\mathbf{w}_{MAP}) - t_n \}^2\]

<p>로 주어진다.</p>

<p>Linear model에서 처럼 이제 alternating optimization을 통해 최적의 hyperparameter를 찾을 수 있지만, neural network의 nonlinearity로 인해 $\mathbf{w}$의 첫 initialization에 따라 최적의 hyperparameter가 달라질 수 있다.</p>

<p>다른 개수의 hidden units를 가진 model들 간의 비교와 같이 모델 간 비교를 위해서는 model evidence 
$p(\mathbf{D}|\alpha,\beta)$
를 비교할 수 있다. 하지만 5.1.1절에서 보았듯 $M$을 hidden units의 개수라고 할 때 two-layer network는 
$M!2^{M}$
만큼의 equivalent modes가 존재하기 때문에 evidence에 
$M!2_{M}$
만큼의 값을 곱해줘야 정확한 비교를 할 수 있을 것이다.</p>

<h3 id="573-bayesian-neural-networks-for-classification">5.7.3 Bayesian neural networks for classification</h3>

<p>이제 two-class classifiction을 위한 neural network에 Bayesian treatment를 적용하는 방법을 살펴보고자 한다. Log likelihood function은</p>

\[ln \ p(\mathbf{D}|\mathbf{w}) = \sum_{n = 1}^{N}\{ t_n ln \ y_n + (1 - t_n) ln(1 - y_n) \}\]

<p>으로 주어질 것이고, $\mathbf{w}$에 대한 prior는 regression 때와 동일하게 주어졌다고 가정하자. 이제 5.7.2절에서와 동일한 방식으로 Bayesian neural network를 construct 할 수 있다. 먼저 $\mathbf{w}_{MAP}$를 구한 뒤, Hessian $\mathbf{H}$를 구하자. 이후에는 동일하게 Laplace approximation을 통해 posterior에 대한 Gaussian approximation이 가능하다.</p>

<p>Hyperparameter $\alpha$에 대한 optimization을 위해 다시 marginal likelihood를 Laplace approximation을 통해</p>

\[ln \ p(\mathbf{D}|\alpha) \simeq -E(\mathbf{w}_{MAP}) - \cfrac{1}{2} ln \ |\mathbf{A}| + \cfrac{W}{2} ln \ \alpha + \text{const}\]

<p>where</p>

\[E(\mathbf{w}) = - ln \ p(\mathbf{D}|\mathbf{w}) + \cfrac{\alpha}{2}\mathbf{w}^{T}\mathbf{w}\]

<p>으로 구할 수 있다. 이를 $\alpha$에 대해 maximize 하면 다시</p>

\[\alpha = \cfrac{\gamma}{\mathbf{w}_{MAP}^{T}\mathbf{w}_{MAP}}\]

<p>로 구해짐을 알 수 있다.</p>

<p>이제 마지막으로 predictive distribution을 구해야한다. 여기서도 역시 적분이 intractable하기 때문에 approximation을 사용해야 한다. 가장 간단한 방법은 posterior distribution이 굉장히 narrow 하다고 가정하고,</p>

\[p(t|\mathbf{x},\mathbf{D}) \simeq p(t|\mathbf{x},\mathbf{w}_{MAP})\]

<p>로 두는 것이다.</p>

<p>더 좋은 방법은 posterior distribution의 variance를 감안하는 것인데, logistic activation function으로 인해 regression에서 처럼 network output을 linear하게 approximate할 수는 없다. 이에 output unit activation에 대한 linear approximation</p>

\[a(\mathbf{x},\mathbf{w}) \simeq a(\mathbf{x},\mathbf{w}_{MAP}) + \mathbf{b}^{T}(\mathbf{w} - \mathbf{w}_{MAP})\]

<p>where</p>

\[\mathbf{b} \equiv \bigtriangledown a(\mathbf{x},\mathbf{w}_{MAP})\]

<p>을 대신 이용하자.</p>

<p>이제 posterior distribution도 Gaussian approximate 되었고, $a$가 $\mathbf{w}$에 대한 linear function이기 때문에 4.5.2절의 결과를 통해</p>

\[p(a|\mathbf{x},\mathbf{D}) = \int \delta(a - a(\mathbf{x},\mathbf{w}_{MAP}) - \mathbf{b}^{T}(\mathbf{x})(\mathbf{w}- \mathbf{w}_{MAP}))q(\mathbf{w|\mathbf{D}})d\mathbf{w}\]

<p>로 주어지며 이 분포가 평균을 $a(\mathbf{x},\mathbf{w}_{MAP})$로 분산을</p>

\[\sigma_{a}^{2}(\mathbf{x}) = \mathbf{b}^{T}(\mathbf{x})\mathbf{A}^{-1}\mathbf{b}(\mathbf{x})\]

<p>로 갖는 Gaussian distribution 이라는 것을 알 수 있다.</p>

<p>마지막으로 predictive distribution를</p>

\[p(t = 1| \mathbf{x},\mathbf{D}) = \int \sigma(a) p (a|\mathbf{x},\mathbf{D})da\]

<p>로 구할 수 있다. 하지만 Gaussian 과 logistic sigmoid간의 convolution은 intractable 하기 때문에 다시 4.5.2절의 approximation을 이용해</p>

\[p(t = 1| \mathbf{x},\mathbf{D}) = \sigma \big( \kappa(\sigma_{a}^2)\mathbf{b}^{T}\mathbf{w}_{MAP} \big)\]

<p>where</p>

\[\kappa(\sigma^2) = (1 + \pi\sigma^2/8)^{-1/2}\]

<p>로 구할 수 있다.</p>
:ET